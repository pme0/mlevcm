}else{
B_opt <- 1
}
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"GLM"),  "K/P"] <- B_opt
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), "K/P"] <- B_opt
########
################   OPTIMISE {# components "Q", penalty parameter "lambda"}
########
#---# Cross-validate (Q,lambda)
vec_basis      <- seq(B_opt, B_opt, by=0.2); lb <- length(vec_basis)   #seq(0.2, 1, by=0.2)
paramsByModel <- list(pls = list(comp_p   = floor(seq(16, 40, len=10)), lam_p   = round(seq(0.5,  10,  len=10), 1),
comp_sp  = floor(seq(16, 30, len=10)), lam_sp  = round(seq(50,   100, len=10), 1),
comp_fp  = floor(seq(16, 30, len=10)), lam_fp  = round(seq(25,   100, len=10), 1),
comp_fsp = floor(seq(10, 30, len=10)), lam_fsp = round(seq(5,    150, len=10), 1)),
pca = list(comp_p   = floor(seq(30, 80, len=10)), lam_p   = round(seq(0.5,  10,  len=10), 1),
comp_sp  = floor(seq(16, 50, len=10)), lam_sp  = round(seq(0.5,  150, len=10), 1),
comp_fp  = floor(seq(10, 46, len=10)), lam_fp  = round(seq(0.5,  50,  len=10), 1),
comp_fsp = floor(seq(6,  50, len=10)), lam_fsp = round(seq(0.05, 15,  len=10), 1)))
vec_components <- paramsByModel[[L_reduction]][[paste0("comp_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), "p")]];  lc <- length(vec_components)
vec_lambdas    <- paramsByModel[[L_reduction]][[paste0("lam_",  ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), "p")]];  ll <- length(vec_lambdas)
#vec_lambdas    <- round(exp(seq(log(2), log(100), len=10))); ll <- length(vec_lambdas)
arr_acc <- arr_acc_stdev <- array(NA, c(length(vec_components), length(vec_lambdas), length(vec_basis)), dimnames=list(paste0("c_",vec_components), paste0("l_",vec_lambdas), paste0("b_",vec_basis)))
arr_rough <- arr_roughStd <- arr_acc
if(L_load){ # load data
loadedData <- readRDS(file=paste0(loc_data, DATA_TYPE, "_CV_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"), ".Rdata"))
arr_acc <- loadedData$arr_acc;  arr_acc_stdev <- loadedData$arr_acc_stdev;  arr_rough <- loadedData$arr_rough;  arr_roughStd <- loadedData$arr_roughStd;  vec_basis <- loadedData$vec_basis;  vec_components <- loadedData$vec_components;  vec_lambdas <- loadedData$vec_lambdas
}else{
cat("",paste0("Parameter set ",(iii+1),"/", n_modelTypes, " (vr=", L_reduction, ",vs=", ifelse(L_smooth==T,"T","F"), ",vf=", ifelse(L_functional==T,"T","F") ,") | CROSS-VALIDATING Q/LAMBDA:"), sep="\n")
pb_cv = txtProgressBar(min = 0, max = lb*lc*ll, initial = 0, style = 3);   loopCounter <- 0
for(nb in 1:lb){
for(nc in 1:lc){
for(nl in 1:ll){
set.seed(17571);  obj <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth=F, intercept=T, lam_cv_type="ocv", lam_vec=vec_lambdas[nl], reps=N_reps, Q_len=NULL, Q_opt=vec_components[nc], Q_vec=NULL, split_size=0.5, Q_opt_threshold=0.01, balanced=F, weighted=F, weights=NULL, Bspline_dim=floor(vec_basis[nb] * ncol(X)), t_range=wvlenghts, verbose=F))
arr_acc[nc,nl,nb] <- mean(obj$perf_cv[,which(obj$Q_vec == obj$Q_opt)])
arr_acc_stdev[nc,nl,nb] <- sd(obj$perf_cv[,which(obj$Q_vec == obj$Q_opt)])
arr_rough[nc,nl,nb] <- mean(obj$beta_roughness)
arr_roughStd[nc,nl,nb] <- mean(obj$beta_roughnessStd)
loopCounter <- loopCounter + 1;   setTxtProgressBar(pb_cv, loopCounter)
}
}
}
cv_list <- list(arr_acc = arr_acc,
arr_acc_stdev = arr_acc_stdev,
arr_rough = arr_rough,
arr_roughStd = arr_roughStd,
vec_basis = vec_basis,
vec_components = vec_components,
vec_lambdas = vec_lambdas)
saveRDS(cv_list, file=paste0(loc_data, DATA_TYPE,"_CV_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"), ".Rdata"))
}
#---# Diagnostic plots
# set.seed(17571);  obj_dgnostics <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth=F, intercept=T, lam_cv_type="n", lam_vec=NULL, reps=N_reps, Q_len=NULL, Q_opt=NULL, Q_vec=NULL, split_size=0.5, Q_opt_threshold=0.01, balanced=F, weighted=F, weights=NULL, Bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=T))
# fdaPlot(obj_dgnostics)
#---# Determine parameter region for ensemble meodel
B_id <- 1 # this is the first (and only) element of 'arr_acc' and similar arrays, because 'vec_basis' only has the optimal pre-computed ratio K/P = B_opt
matrix_acc <- arr_acc[,,B_id]
tau_lam_Q <- 0.01
n_acceptable <- 25  # maximum number of models in the acceptable region
n_ensemble   <- 5   # maximum number of models in the ensemble (most SMOOTH from the models in the acceptable region)
if(n_ensemble > n_acceptable){ stop("'n_acceptable' must be larger or equal to 'n_ensemble'.") }
# compute acceptable region
if(L_model == "lm"){
stop("REVISE OPTIMAL REGION FORMULA + MULTIPLE MODELS NOT CODED YET.")
acceptable_region <- which( (matrix_acc - min(matrix_acc)) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA); colnames(acceptable_region) <- c("components","lambda","roughness")
}else if (L_model == "glm"){
acceptable_region <- which( (max(matrix_acc) - matrix_acc) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA,NA); colnames(acceptable_region) <- c("components","lambda","roughness","acc")
}
for(q in 1:nr){
acceptable_region[q,"roughness"] <- arr_roughStd[acceptable_region[q,"components"], acceptable_region[q,"lambda"], B_id]
acceptable_region[q,"acc"] <- matrix_acc[acceptable_region[q,"components"], acceptable_region[q,"lambda"]]
}
# order by 'acc' and select top 'n_acceptable'
acceptable_region <- acceptable_region[order(acceptable_region[,"acc"], decreasing=T),]
if(nrow(acceptable_region) > n_acceptable){ acceptable_region <- acceptable_region[1:n_acceptable,] # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_acceptable'
}else{                                      n_acceptable <- nrow(acceptable_region) }
if(n_acceptable < n_ensemble){ n_ensemble <- n_acceptable } # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_ensemble'
# re-order by increasing roughness
acceptable_region <- acceptable_region[order(acceptable_region[,"roughness"]),]
# select best models
best_combo_IDs <- acceptable_region[, c("components","lambda")]
best_combo <- cbind(vec_components[best_combo_IDs[,"components"]], vec_lambdas[best_combo_IDs[,"lambda"]]); colnames(best_combo) <- c("Q_opt", "lam_opt")
#---# Levelplot for accuracy and roughness
brewer.div <- colorRampPalette(brewer.pal(11, "Spectral"), interpolate = "spline")
precision <- 3  # decimal places
plotMe_acc <- round(arr_acc[,,B_id], precision); rownames(plotMe_acc) <- vec_components; colnames(plotMe_acc) <- round(vec_lambdas,2)
plotMe_rough <- arr_roughStd[,,B_id]; rownames(plotMe_rough) <- vec_components; colnames(plotMe_rough) <- round(vec_lambdas,2)
# accuracy plot
# pdf(file = paste0(loc_figures, "fig_MAP_accuracy2.pdf"), height=5, width=5, pointsize=12)
colors_at <- seq(floor((10^precision)*min(plotMe_acc))/(10^precision), ceiling((10^precision)*max(plotMe_acc))/(10^precision), len=16)
the_labels <- round(colors_at,3);   the_labels[c(2,3,5,6,8,9,11,12,14,15)] <- ""
levelplot(plotMe_acc, at=colors_at, panel=crossvalidation_levelplot, letter=list(char="a", xloc=1, yloc=ncol(plotMe_acc)), col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="AUC map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
# roughness plot
# pdf(file = paste0(loc_figures, "fig_MAP_roughness2.pdf", height=5, width=5, pointsize=12)
colors_at <- exp(seq(log(min(plotMe_rough)*0.95), log(max(plotMe_rough)*1.05), len=16))
the_labels <- round(colors_at,2);   the_labels[c(2,3,4,5,6,7,8,10,12)] <- ""
levelplot(plotMe_rough, at=colors_at, panel=crossvalidation_levelplot, letter=list(char="b", xloc=1, yloc=ncol(plotMe_acc)), col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="ROUGHNESS map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
if( !(max(matrix_acc) - matrix_acc[best_combo_IDs[1,"components"], best_combo_IDs[1,"lambda"]] <= tau_lam_Q) ){ stop("Closeness criterion not satisfied!") }   # check that the result satisfies the criterion
#---# Test optimal and sub-optimal
cat("",paste0("Parameter set ",(iii+1),"/",n_modelTypes, " (vr=", L_reduction, ",vs=", ifelse(L_smooth==T,"T","F"), ",vf=", ifelse(L_functional==T,"T","F") ,") | COMPUTING OPTIMAL AND SUBOPTIMAL MODELS:"), sep="\n")
pb_subopt = txtProgressBar(min = 0, max = n_ensemble+1, initial = 0, style = 3)
set.seed(17571);  obj_std <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth=F, intercept=T, lam_cv_type="n", lam_vec=NULL, reps=N_reps, Q_len=NULL, Q_opt=NULL, Q_vec=NULL, split_size=0.5, Q_opt_threshold=0.01, balanced=F, weighted=F, weights=NULL, Bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=F))
setTxtProgressBar(pb_subopt, 1)
suboptimal_MODELS <- list(); suboptimal_RES <- matrix(NA, n_ensemble, 8); colnames(suboptimal_RES) <- c("Q", "R", "lam", "acc", "err_cv", "err_cv_stdev", "err_alt", "err_alt_stdev")
for(jj in 1:n_ensemble){
set.seed(17571);  obj_opt <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth=F, intercept=T, lam_cv_type="ocv", lam_vec=best_combo[jj,"lam_opt"], reps=N_reps, Q_len=NULL, Q_opt=best_combo[jj,"Q_opt"], Q_vec=NULL, split_size=0.5, Q_opt_threshold=0.01, balanced=F, weighted=F, weights=NULL, Bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=F))
suboptimal_RES[jj,"Q"] <- obj_opt$Q_opt
suboptimal_RES[jj,"R"] <- GET_roughness(rowMeans(obj_opt$beta), std=T)
suboptimal_RES[jj,"lam"] <- obj_opt$lam_opt
suboptimal_RES[jj,"acc"] <- mean(obj_opt$AUC_opt[,"test"])
suboptimal_RES[jj,"err_cv"] <- fdaPlot(obj_opt)$err
suboptimal_RES[jj,"err_cv_stdev"] <- fdaPlot(obj_opt)$err_stdev
suboptimal_MODELS[[jj]] <- obj_opt
setTxtProgressBar(pb_subopt, jj+1)
}
# fdaPlot(obj_std, hist_range=c(-20,20))
# fdaPlot(obj_opt)
#{"Q","R","lambda","acc"}
if(L_model == "lm"){
stop("NOT CODED YET! calls 'obj_std$AUC_opt' but that only works for GLM.")
}else if(L_model == "glm"){
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"GLM"),  c("Q","R","lambda","acc","err_cv_smoothest","err_cv_stdev_smoothest")] <- c(obj_std$Q_opt, GET_roughness(rowMeans(obj_std$beta), std=T), obj_std$lam_opt, mean(obj_std$AUC_opt[,"test"]), fdaPlot(obj_std)$err, fdaPlot(obj_std)$err_stdev) # for the non-penalised model, we record the error in the 'smoothest' column, although there's only one model here (lambda=0)
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("Q","R","lambda","acc","err_cv_smoothest","err_cv_stdev_smoothest","err_cv_ensemble","err_cv_stdev_ensemble")] <- c(mean(suboptimal_RES[,"Q"]), mean(suboptimal_RES[,"R"]), mean(suboptimal_RES[,"lam"]), mean(suboptimal_RES[,"acc"]), unname(suboptimal_RES[1,"err_cv"]), unname(suboptimal_RES[1,"err_cv_stdev"]), mean(suboptimal_RES[,"err_cv"]), mean(suboptimal_RES[,"err_cv_stdev"]))
}
#---# P-values for non-functional variable
# ii_Zpvalues <- (raw_data[,"Species"] %in% SPE) & (raw_data[,"Location"] %in% c(LOC_train,LOC_test)) & (raw_data[,"Generation"] %in% GEN_train)
# balanced_classes <- T
# set.seed(17571);  obj_Zpvalues <- fdaML_train(ll = list(X=X[ii_Zpvalues,], y=factor(y[ii_Zpvalues]), Z=matrix(as.numeric(raw_data[ii_Zpvalues,"Location",drop=F] == "Klesso"), sum(ii_Zpvalues), 1), task=L_task, model=L_model, reduction=L_reduction, smooth=F, intercept=T, lam_cv_type="n", lam_vec=NULL, reps=N_reps, Q_len=NULL, Q_opt=NULL, Q_vec=NULL, split_size=0.5, Q_opt_threshold=0.01, balanced=balanced_classes, weighted=F, weights=NULL, Bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=T))
# plot(obj_Zpvalues$Z_pvalue);  abline(h=0.05, lwd=2);  legend("topright", legend=paste0("median p-value = ", round(median(obj_Zpvalues$Z_pvalue),3)), bty="n", cex=0.9)
#---# Test with alternative dataset
#ii <- (raw_data[,"Feeding_status"] == "Exposed") & (raw_data[,"Infection_status"] %in% c("infectious","uninfectious")) & (raw_data[,"Scanning_day"] %in% c(17,19))
#X_subset_alt <- X[ii,];  y_subset_alt <- rep(0, sum(ii));  y_subset_alt[y[ii] == "infectious"] <- 1;
#
if(DATA_TYPE == "species_A1T1"){
# test with alternative dataset (species_A1T1)
GEN_test <- c("F0", "F1")
ii <- (raw_data[,"Species"] %in% SPE) & (raw_data[,"Location"] %in% LOC_test) & (raw_data[,"Generation"] %in% GEN_train)
X_subset_alt <- X[ii,];  y_subset_alt <- rep(0, sum(ii));  y_subset_alt[raw_data[ii,"Species"] == SPE[1]] <- 1
}else if(DATA_TYPE == "age"){
# test with alternative dataset (age)
ii <- (raw_data[,"Species"] %in% c("gambiae"))
X_subset_alt <- X[ii,];  y_subset_alt <- y[ii]
locTest <- "--"
}else{
stop("'DATA_TYPE' invalid.")
}
cat("",paste0("Parameter set ",(iii+1),"/", n_modelTypes, " (vr=", L_reduction, ",vs=", ifelse(L_smooth==T,"T","F"), ",vf=", ifelse(L_functional==T,"T","F") ,") | TESTING ALTERNATIVE DATASET:"), sep="\n")
pb_alt = txtProgressBar(min = 0, max = n_ensemble+1, initial = 0, style = 3)
set.seed(17571);  obj_alt_penNOP <- fdaML_predict(obj = obj_std, new_x = X_subset_alt, new_y = y_subset_alt, verbose=F)
setTxtProgressBar(pb_alt, 1)
# obj_alt_penNOP$errorBreakdown   # confusion matrix
alternative_MODELS <- list()
for(jj in 1:n_ensemble){
set.seed(17571);  obj_alt_penYEP <- fdaML_predict(obj = suboptimal_MODELS[[jj]], new_x = X_subset_alt, new_y = y_subset_alt, verbose=F)
# obj_alt_penYEP$errorBreakdown   # confusion matrix
#alternative_MODELS[[jj]] <- alternativeMODELS
suboptimal_RES[jj,"err_alt"] <- obj_alt_penYEP$avgTestErr
suboptimal_RES[jj,"err_alt_stdev"] <- obj_alt_penYEP$stdevTestErr
setTxtProgressBar(pb_alt, jj+1)
}
# re-order by increasing roughness
#suboptimal_RES <- suboptimal_RES[order(suboptimal_RES[,"R"]),]
write.table(x = round(suboptimal_RES, 8), file = paste0(loc_data, DATA_TYPE, "_suboptimalRESULTS_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), "p", toupper(L_model) ,"_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
#fdaPlot(obj_alt_penNOP)
#fdaPlot(obj_alt_penYEP)
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""), "GLM"), c("err_alt_smoothest", "err_alt_stdev_smoothest")] <- c(obj_alt_penNOP$avgTestErr, obj_alt_penNOP$stdevTestErr) # for the non-penalised model, we record the error in the 'smoothest' column, although there's only one model here (lambda=0)
#ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("err_alt", "err_alt_stdev")] <- c(obj_alt_penYEP$avgTestErr, obj_alt_penYEP$stdevTestErr)
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("err_alt_smoothest", "err_alt_stdev_smoothest", "err_alt_ensemble", "err_alt_stdev_ensemble")] <- c(suboptimal_RES[1,"err_alt"], suboptimal_RES[1,"err_alt_stdev"], mean(suboptimal_RES[,"err_alt"]), mean(suboptimal_RES[jj,"err_alt_stdev"]))
#---# save summary results
iii <- iii + 1
if(DATA_TYPE == "species_A1T1"){
#saveRDS(ALL_RES, file=paste0(loc_data, DATA_TYPE,"_RESULTS__GLM_",toupper(L_reduction), "_", get_fname(SPE,"spe"), "_TrainOn_", LOC_train, get_fname(GEN_train,"gen"),"_TestOn_", LOC_test, get_fname(GEN_test,"gen"), "__iii-", iii, ".Rdata"))
write.table(x = round(ALL_RES,8), file = paste0(loc_data, DATA_TYPE,"_summaryRESULTS_", toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
}else if(DATA_TYPE == "age"){
write.table(x = round(ALL_RES,8), file = paste0(loc_data, DATA_TYPE,"_summaryRESULTS_", toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
}
ALL_RES
colors_at <- seq(floor((10^precision)*min(plotMe_acc))/(10^precision), ceiling((10^precision)*max(plotMe_acc))/(10^precision), len=16)
the_labels <- round(colors_at,3);   the_labels[c(2,3,5,6,8,9,11,12,14,15)] <- ""
levelplot(plotMe_acc, at=colors_at, panel=crossvalidation_levelplot, letter=list(char="a", xloc=1, yloc=ncol(plotMe_acc)), col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="AUC map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
vf
vs
loadedData <- readRDS(file=paste0(loc_data, DATA_TYPE, "_CV_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"), ".Rdata"))
arr_acc <- loadedData$arr_acc;  arr_acc_stdev <- loadedData$arr_acc_stdev;  arr_rough <- loadedData$arr_rough;  arr_roughStd <- loadedData$arr_roughStd;  vec_basis <- loadedData$vec_basis;  vec_components <- loadedData$vec_components;  vec_lambdas <- loadedData$vec_lambdas
B_id <- 1 # this is the first (and only) element of 'arr_acc' and similar arrays, because 'vec_basis' only has the optimal pre-computed ratio K/P = B_opt
matrix_acc <- arr_acc[,,B_id]
tau_lam_Q <- 0.01
n_acceptable <- 25  # maximum number of models in the acceptable region
n_ensemble   <- 5   # maximum number of models in the ensemble (most SMOOTH from the models in the acceptable region)
if(n_ensemble > n_acceptable){ stop("'n_acceptable' must be larger or equal to 'n_ensemble'.") }
# compute acceptable region
if(L_model == "lm"){
stop("REVISE OPTIMAL REGION FORMULA + MULTIPLE MODELS NOT CODED YET.")
acceptable_region <- which( (matrix_acc - min(matrix_acc)) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA); colnames(acceptable_region) <- c("components","lambda","roughness")
}else if (L_model == "glm"){
acceptable_region <- which( (max(matrix_acc) - matrix_acc) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA,NA); colnames(acceptable_region) <- c("components","lambda","roughness","acc")
}
for(q in 1:nr){
acceptable_region[q,"roughness"] <- arr_roughStd[acceptable_region[q,"components"], acceptable_region[q,"lambda"], B_id]
acceptable_region[q,"acc"] <- matrix_acc[acceptable_region[q,"components"], acceptable_region[q,"lambda"]]
}
# order by 'acc' and select top 'n_acceptable'
acceptable_region <- acceptable_region[order(acceptable_region[,"acc"], decreasing=T),]
if(nrow(acceptable_region) > n_acceptable){ acceptable_region <- acceptable_region[1:n_acceptable,] # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_acceptable'
}else{                                      n_acceptable <- nrow(acceptable_region) }
if(n_acceptable < n_ensemble){ n_ensemble <- n_acceptable } # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_ensemble'
# re-order by increasing roughness
acceptable_region <- acceptable_region[order(acceptable_region[,"roughness"]),]
# select best models
best_combo_IDs <- acceptable_region[, c("components","lambda")]
best_combo <- cbind(vec_components[best_combo_IDs[,"components"]], vec_lambdas[best_combo_IDs[,"lambda"]]); colnames(best_combo) <- c("Q_opt", "lam_opt")
#---# Levelplot for accuracy and roughness
brewer.div <- colorRampPalette(brewer.pal(11, "Spectral"), interpolate = "spline")
precision <- 3  # decimal places
plotMe_acc <- round(arr_acc[,,B_id], precision); rownames(plotMe_acc) <- vec_components; colnames(plotMe_acc) <- round(vec_lambdas,2)
plotMe_rough <- arr_roughStd[,,B_id]; rownames(plotMe_rough) <- vec_components; colnames(plotMe_rough) <- round(vec_lambdas,2)
# accuracy plot
# pdf(file = paste0(loc_figures, "fig_MAP_accuracy2.pdf"), height=5, width=5, pointsize=12)
colors_at <- seq(floor((10^precision)*min(plotMe_acc))/(10^precision), ceiling((10^precision)*max(plotMe_acc))/(10^precision), len=16)
the_labels <- round(colors_at,3);   the_labels[c(2,3,5,6,8,9,11,12,14,15)] <- ""
levelplot(plotMe_acc, at=colors_at, panel=crossvalidation_levelplot, letter=list(char="a", xloc=1, yloc=ncol(plotMe_acc)), col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="AUC map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
vs
vf
vs=T
loadedData <- readRDS(file=paste0(loc_data, DATA_TYPE, "_CV_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"), ".Rdata"))
arr_acc <- loadedData$arr_acc;  arr_acc_stdev <- loadedData$arr_acc_stdev;  arr_rough <- loadedData$arr_rough;  arr_roughStd <- loadedData$arr_roughStd;  vec_basis <- loadedData$vec_basis;  vec_components <- loadedData$vec_components;  vec_lambdas <- loadedData$vec_lambdas
B_id <- 1 # this is the first (and only) element of 'arr_acc' and similar arrays, because 'vec_basis' only has the optimal pre-computed ratio K/P = B_opt
matrix_acc <- arr_acc[,,B_id]
tau_lam_Q <- 0.01
n_acceptable <- 25  # maximum number of models in the acceptable region
n_ensemble   <- 5   # maximum number of models in the ensemble (most SMOOTH from the models in the acceptable region)
if(n_ensemble > n_acceptable){ stop("'n_acceptable' must be larger or equal to 'n_ensemble'.") }
# compute acceptable region
if(L_model == "lm"){
stop("REVISE OPTIMAL REGION FORMULA + MULTIPLE MODELS NOT CODED YET.")
acceptable_region <- which( (matrix_acc - min(matrix_acc)) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA); colnames(acceptable_region) <- c("components","lambda","roughness")
}else if (L_model == "glm"){
acceptable_region <- which( (max(matrix_acc) - matrix_acc) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA,NA); colnames(acceptable_region) <- c("components","lambda","roughness","acc")
}
for(q in 1:nr){
acceptable_region[q,"roughness"] <- arr_roughStd[acceptable_region[q,"components"], acceptable_region[q,"lambda"], B_id]
acceptable_region[q,"acc"] <- matrix_acc[acceptable_region[q,"components"], acceptable_region[q,"lambda"]]
}
# order by 'acc' and select top 'n_acceptable'
acceptable_region <- acceptable_region[order(acceptable_region[,"acc"], decreasing=T),]
if(nrow(acceptable_region) > n_acceptable){ acceptable_region <- acceptable_region[1:n_acceptable,] # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_acceptable'
}else{                                      n_acceptable <- nrow(acceptable_region) }
if(n_acceptable < n_ensemble){ n_ensemble <- n_acceptable } # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_ensemble'
# re-order by increasing roughness
acceptable_region <- acceptable_region[order(acceptable_region[,"roughness"]),]
# select best models
best_combo_IDs <- acceptable_region[, c("components","lambda")]
best_combo <- cbind(vec_components[best_combo_IDs[,"components"]], vec_lambdas[best_combo_IDs[,"lambda"]]); colnames(best_combo) <- c("Q_opt", "lam_opt")
#---# Levelplot for accuracy and roughness
brewer.div <- colorRampPalette(brewer.pal(11, "Spectral"), interpolate = "spline")
precision <- 3  # decimal places
plotMe_acc <- round(arr_acc[,,B_id], precision); rownames(plotMe_acc) <- vec_components; colnames(plotMe_acc) <- round(vec_lambdas,2)
plotMe_rough <- arr_roughStd[,,B_id]; rownames(plotMe_rough) <- vec_components; colnames(plotMe_rough) <- round(vec_lambdas,2)
# accuracy plot
# pdf(file = paste0(loc_figures, "fig_MAP_accuracy2.pdf"), height=5, width=5, pointsize=12)
colors_at <- seq(floor((10^precision)*min(plotMe_acc))/(10^precision), ceiling((10^precision)*max(plotMe_acc))/(10^precision), len=16)
the_labels <- round(colors_at,3);   the_labels[c(2,3,5,6,8,9,11,12,14,15)] <- ""
levelplot(plotMe_acc, at=colors_at, panel=crossvalidation_levelplot, letter=list(char="a", xloc=1, yloc=ncol(plotMe_acc)), col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="AUC map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
vf
vs
vf
vs
loadedData <- readRDS(file=paste0(loc_data, DATA_TYPE, "_CV_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"), ".Rdata"))
arr_acc <- loadedData$arr_acc;  arr_acc_stdev <- loadedData$arr_acc_stdev;  arr_rough <- loadedData$arr_rough;  arr_roughStd <- loadedData$arr_roughStd;  vec_basis <- loadedData$vec_basis;  vec_components <- loadedData$vec_components;  vec_lambdas <- loadedData$vec_lambdas
L_functional
L_smooth
L_smooth=T
L_functional=T; L_smooth=T
loadedData <- readRDS(file=paste0(loc_data, DATA_TYPE, "_CV_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"), ".Rdata"))
arr_acc <- loadedData$arr_acc;  arr_acc_stdev <- loadedData$arr_acc_stdev;  arr_rough <- loadedData$arr_rough;  arr_roughStd <- loadedData$arr_roughStd;  vec_basis <- loadedData$vec_basis;  vec_components <- loadedData$vec_components;  vec_lambdas <- loadedData$vec_lambdas
B_id <- 1 # this is the first (and only) element of 'arr_acc' and similar arrays, because 'vec_basis' only has the optimal pre-computed ratio K/P = B_opt
matrix_acc <- arr_acc[,,B_id]
tau_lam_Q <- 0.01
n_acceptable <- 25  # maximum number of models in the acceptable region
n_ensemble   <- 5   # maximum number of models in the ensemble (most SMOOTH from the models in the acceptable region)
if(n_ensemble > n_acceptable){ stop("'n_acceptable' must be larger or equal to 'n_ensemble'.") }
# compute acceptable region
if(L_model == "lm"){
stop("REVISE OPTIMAL REGION FORMULA + MULTIPLE MODELS NOT CODED YET.")
acceptable_region <- which( (matrix_acc - min(matrix_acc)) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA); colnames(acceptable_region) <- c("components","lambda","roughness")
}else if (L_model == "glm"){
acceptable_region <- which( (max(matrix_acc) - matrix_acc) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA,NA); colnames(acceptable_region) <- c("components","lambda","roughness","acc")
}
for(q in 1:nr){
acceptable_region[q,"roughness"] <- arr_roughStd[acceptable_region[q,"components"], acceptable_region[q,"lambda"], B_id]
acceptable_region[q,"acc"] <- matrix_acc[acceptable_region[q,"components"], acceptable_region[q,"lambda"]]
}
# order by 'acc' and select top 'n_acceptable'
acceptable_region <- acceptable_region[order(acceptable_region[,"acc"], decreasing=T),]
if(nrow(acceptable_region) > n_acceptable){ acceptable_region <- acceptable_region[1:n_acceptable,] # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_acceptable'
}else{                                      n_acceptable <- nrow(acceptable_region) }
if(n_acceptable < n_ensemble){ n_ensemble <- n_acceptable } # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_ensemble'
# re-order by increasing roughness
acceptable_region <- acceptable_region[order(acceptable_region[,"roughness"]),]
# select best models
best_combo_IDs <- acceptable_region[, c("components","lambda")]
best_combo <- cbind(vec_components[best_combo_IDs[,"components"]], vec_lambdas[best_combo_IDs[,"lambda"]]); colnames(best_combo) <- c("Q_opt", "lam_opt")
#---# Levelplot for accuracy and roughness
brewer.div <- colorRampPalette(brewer.pal(11, "Spectral"), interpolate = "spline")
precision <- 3  # decimal places
plotMe_acc <- round(arr_acc[,,B_id], precision); rownames(plotMe_acc) <- vec_components; colnames(plotMe_acc) <- round(vec_lambdas,2)
plotMe_rough <- arr_roughStd[,,B_id]; rownames(plotMe_rough) <- vec_components; colnames(plotMe_rough) <- round(vec_lambdas,2)
# accuracy plot
# pdf(file = paste0(loc_figures, "fig_MAP_accuracy2.pdf"), height=5, width=5, pointsize=12)
colors_at <- seq(floor((10^precision)*min(plotMe_acc))/(10^precision), ceiling((10^precision)*max(plotMe_acc))/(10^precision), len=16)
the_labels <- round(colors_at,3);   the_labels[c(2,3,5,6,8,9,11,12,14,15)] <- ""
levelplot(plotMe_acc, at=colors_at, panel=crossvalidation_levelplot, letter=list(char="a", xloc=1, yloc=ncol(plotMe_acc)), col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="AUC map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
round(colors_at,3)
colors_at
the_labels
colors_at
best_combo_IDs[,"components"]
best_combo_IDs[,"lambda"]
plotMe_acc
floor(seq(6,  50, len=10))
best_combo
round(seq(0.05, 15,  len=10), 1)
round(seq(0.051, 15,  len=10), 1)
round(seq(0.5,   150, len=10), 1)
L_functional=T; L_smooth=T
loadedData <- readRDS(file=paste0(loc_data, DATA_TYPE, "_CV_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"), ".Rdata"))
arr_acc <- loadedData$arr_acc;  arr_acc_stdev <- loadedData$arr_acc_stdev;  arr_rough <- loadedData$arr_rough;  arr_roughStd <- loadedData$arr_roughStd;  vec_basis <- loadedData$vec_basis;  vec_components <- loadedData$vec_components;  vec_lambdas <- loadedData$vec_lambdas
B_id <- 1 # this is the first (and only) element of 'arr_acc' and similar arrays, because 'vec_basis' only has the optimal pre-computed ratio K/P = B_opt
matrix_acc <- arr_acc[,,B_id]
tau_lam_Q <- 0.01
n_acceptable <- 25  # maximum number of models in the acceptable region
n_ensemble   <- 5   # maximum number of models in the ensemble (most SMOOTH from the models in the acceptable region)
if(n_ensemble > n_acceptable){ stop("'n_acceptable' must be larger or equal to 'n_ensemble'.") }
# compute acceptable region
if(L_model == "lm"){
stop("REVISE OPTIMAL REGION FORMULA + MULTIPLE MODELS NOT CODED YET.")
acceptable_region <- which( (matrix_acc - min(matrix_acc)) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA); colnames(acceptable_region) <- c("components","lambda","roughness")
}else if (L_model == "glm"){
acceptable_region <- which( (max(matrix_acc) - matrix_acc) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA,NA); colnames(acceptable_region) <- c("components","lambda","roughness","acc")
}
for(q in 1:nr){
acceptable_region[q,"roughness"] <- arr_roughStd[acceptable_region[q,"components"], acceptable_region[q,"lambda"], B_id]
acceptable_region[q,"acc"] <- matrix_acc[acceptable_region[q,"components"], acceptable_region[q,"lambda"]]
}
# order by 'acc' and select top 'n_acceptable'
acceptable_region <- acceptable_region[order(acceptable_region[,"acc"], decreasing=T),]
if(nrow(acceptable_region) > n_acceptable){ acceptable_region <- acceptable_region[1:n_acceptable,] # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_acceptable'
}else{                                      n_acceptable <- nrow(acceptable_region) }
if(n_acceptable < n_ensemble){ n_ensemble <- n_acceptable } # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_ensemble'
# re-order by increasing roughness
acceptable_region <- acceptable_region[order(acceptable_region[,"roughness"]),]
# select best models
best_combo_IDs <- acceptable_region[, c("components","lambda")]
best_combo <- cbind(vec_components[best_combo_IDs[,"components"]], vec_lambdas[best_combo_IDs[,"lambda"]]); colnames(best_combo) <- c("Q_opt", "lam_opt")
#---# Levelplot for accuracy and roughness
brewer.div <- colorRampPalette(brewer.pal(11, "Spectral"), interpolate = "spline")
precision <- 3  # decimal places
plotMe_acc <- round(arr_acc[,,B_id], precision); rownames(plotMe_acc) <- vec_components; colnames(plotMe_acc) <- round(vec_lambdas,2)
plotMe_rough <- arr_roughStd[,,B_id]; rownames(plotMe_rough) <- vec_components; colnames(plotMe_rough) <- round(vec_lambdas,2)
# accuracy plot
# pdf(file = paste0(loc_figures, "fig_MAP_accuracy2.pdf"), height=5, width=5, pointsize=12)
colors_at <- seq(floor((10^precision)*min(plotMe_acc))/(10^precision), ceiling((10^precision)*max(plotMe_acc))/(10^precision), len=16)
the_labels <- round(colors_at,3);   the_labels[c(2,3,5,6,8,9,11,12,14,15)] <- ""
levelplot(plotMe_acc, at=colors_at, panel=crossvalidation_levelplot, letter=list(char="a", xloc=1, yloc=ncol(plotMe_acc)), col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="AUC map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
L_functional=T; L_smooth=F
loadedData <- readRDS(file=paste0(loc_data, DATA_TYPE, "_CV_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"), ".Rdata"))
arr_acc <- loadedData$arr_acc;  arr_acc_stdev <- loadedData$arr_acc_stdev;  arr_rough <- loadedData$arr_rough;  arr_roughStd <- loadedData$arr_roughStd;  vec_basis <- loadedData$vec_basis;  vec_components <- loadedData$vec_components;  vec_lambdas <- loadedData$vec_lambdas
B_id <- 1 # this is the first (and only) element of 'arr_acc' and similar arrays, because 'vec_basis' only has the optimal pre-computed ratio K/P = B_opt
matrix_acc <- arr_acc[,,B_id]
tau_lam_Q <- 0.01
n_acceptable <- 25  # maximum number of models in the acceptable region
n_ensemble   <- 5   # maximum number of models in the ensemble (most SMOOTH from the models in the acceptable region)
if(n_ensemble > n_acceptable){ stop("'n_acceptable' must be larger or equal to 'n_ensemble'.") }
# compute acceptable region
if(L_model == "lm"){
stop("REVISE OPTIMAL REGION FORMULA + MULTIPLE MODELS NOT CODED YET.")
acceptable_region <- which( (matrix_acc - min(matrix_acc)) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA); colnames(acceptable_region) <- c("components","lambda","roughness")
}else if (L_model == "glm"){
acceptable_region <- which( (max(matrix_acc) - matrix_acc) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA,NA); colnames(acceptable_region) <- c("components","lambda","roughness","acc")
}
for(q in 1:nr){
acceptable_region[q,"roughness"] <- arr_roughStd[acceptable_region[q,"components"], acceptable_region[q,"lambda"], B_id]
acceptable_region[q,"acc"] <- matrix_acc[acceptable_region[q,"components"], acceptable_region[q,"lambda"]]
}
# order by 'acc' and select top 'n_acceptable'
acceptable_region <- acceptable_region[order(acceptable_region[,"acc"], decreasing=T),]
if(nrow(acceptable_region) > n_acceptable){ acceptable_region <- acceptable_region[1:n_acceptable,] # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_acceptable'
}else{                                      n_acceptable <- nrow(acceptable_region) }
if(n_acceptable < n_ensemble){ n_ensemble <- n_acceptable } # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_ensemble'
# re-order by increasing roughness
acceptable_region <- acceptable_region[order(acceptable_region[,"roughness"]),]
# select best models
best_combo_IDs <- acceptable_region[, c("components","lambda")]
best_combo <- cbind(vec_components[best_combo_IDs[,"components"]], vec_lambdas[best_combo_IDs[,"lambda"]]); colnames(best_combo) <- c("Q_opt", "lam_opt")
#---# Levelplot for accuracy and roughness
brewer.div <- colorRampPalette(brewer.pal(11, "Spectral"), interpolate = "spline")
precision <- 3  # decimal places
plotMe_acc <- round(arr_acc[,,B_id], precision); rownames(plotMe_acc) <- vec_components; colnames(plotMe_acc) <- round(vec_lambdas,2)
plotMe_rough <- arr_roughStd[,,B_id]; rownames(plotMe_rough) <- vec_components; colnames(plotMe_rough) <- round(vec_lambdas,2)
# accuracy plot
# pdf(file = paste0(loc_figures, "fig_MAP_accuracy2.pdf"), height=5, width=5, pointsize=12)
colors_at <- seq(floor((10^precision)*min(plotMe_acc))/(10^precision), ceiling((10^precision)*max(plotMe_acc))/(10^precision), len=16)
the_labels <- round(colors_at,3);   the_labels[c(2,3,5,6,8,9,11,12,14,15)] <- ""
levelplot(plotMe_acc, at=colors_at, panel=crossvalidation_levelplot, letter=list(char="a", xloc=1, yloc=ncol(plotMe_acc)), col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="AUC map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
L_functional=T; L_smooth=F
L_functional=F; L_smooth=T
loadedData <- readRDS(file=paste0(loc_data, DATA_TYPE, "_CV_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"), ".Rdata"))
arr_acc <- loadedData$arr_acc;  arr_acc_stdev <- loadedData$arr_acc_stdev;  arr_rough <- loadedData$arr_rough;  arr_roughStd <- loadedData$arr_roughStd;  vec_basis <- loadedData$vec_basis;  vec_components <- loadedData$vec_components;  vec_lambdas <- loadedData$vec_lambdas
B_id <- 1 # this is the first (and only) element of 'arr_acc' and similar arrays, because 'vec_basis' only has the optimal pre-computed ratio K/P = B_opt
matrix_acc <- arr_acc[,,B_id]
tau_lam_Q <- 0.01
n_acceptable <- 25  # maximum number of models in the acceptable region
n_ensemble   <- 5   # maximum number of models in the ensemble (most SMOOTH from the models in the acceptable region)
if(n_ensemble > n_acceptable){ stop("'n_acceptable' must be larger or equal to 'n_ensemble'.") }
# compute acceptable region
if(L_model == "lm"){
stop("REVISE OPTIMAL REGION FORMULA + MULTIPLE MODELS NOT CODED YET.")
acceptable_region <- which( (matrix_acc - min(matrix_acc)) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA); colnames(acceptable_region) <- c("components","lambda","roughness")
}else if (L_model == "glm"){
acceptable_region <- which( (max(matrix_acc) - matrix_acc) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA,NA); colnames(acceptable_region) <- c("components","lambda","roughness","acc")
}
for(q in 1:nr){
acceptable_region[q,"roughness"] <- arr_roughStd[acceptable_region[q,"components"], acceptable_region[q,"lambda"], B_id]
acceptable_region[q,"acc"] <- matrix_acc[acceptable_region[q,"components"], acceptable_region[q,"lambda"]]
}
# order by 'acc' and select top 'n_acceptable'
acceptable_region <- acceptable_region[order(acceptable_region[,"acc"], decreasing=T),]
if(nrow(acceptable_region) > n_acceptable){ acceptable_region <- acceptable_region[1:n_acceptable,] # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_acceptable'
}else{                                      n_acceptable <- nrow(acceptable_region) }
if(n_acceptable < n_ensemble){ n_ensemble <- n_acceptable } # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_ensemble'
# re-order by increasing roughness
acceptable_region <- acceptable_region[order(acceptable_region[,"roughness"]),]
# select best models
best_combo_IDs <- acceptable_region[, c("components","lambda")]
best_combo <- cbind(vec_components[best_combo_IDs[,"components"]], vec_lambdas[best_combo_IDs[,"lambda"]]); colnames(best_combo) <- c("Q_opt", "lam_opt")
#---# Levelplot for accuracy and roughness
brewer.div <- colorRampPalette(brewer.pal(11, "Spectral"), interpolate = "spline")
precision <- 3  # decimal places
plotMe_acc <- round(arr_acc[,,B_id], precision); rownames(plotMe_acc) <- vec_components; colnames(plotMe_acc) <- round(vec_lambdas,2)
plotMe_rough <- arr_roughStd[,,B_id]; rownames(plotMe_rough) <- vec_components; colnames(plotMe_rough) <- round(vec_lambdas,2)
# accuracy plot
# pdf(file = paste0(loc_figures, "fig_MAP_accuracy2.pdf"), height=5, width=5, pointsize=12)
colors_at <- seq(floor((10^precision)*min(plotMe_acc))/(10^precision), ceiling((10^precision)*max(plotMe_acc))/(10^precision), len=16)
the_labels <- round(colors_at,3);   the_labels[c(2,3,5,6,8,9,11,12,14,15)] <- ""
levelplot(plotMe_acc, at=colors_at, panel=crossvalidation_levelplot, letter=list(char="a", xloc=1, yloc=ncol(plotMe_acc)), col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="AUC map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
L_functional=F; L_smooth=T
L_functional=F; L_smooth=F
loadedData <- readRDS(file=paste0(loc_data, DATA_TYPE, "_CV_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"), ".Rdata"))
arr_acc <- loadedData$arr_acc;  arr_acc_stdev <- loadedData$arr_acc_stdev;  arr_rough <- loadedData$arr_rough;  arr_roughStd <- loadedData$arr_roughStd;  vec_basis <- loadedData$vec_basis;  vec_components <- loadedData$vec_components;  vec_lambdas <- loadedData$vec_lambdas
B_id <- 1 # this is the first (and only) element of 'arr_acc' and similar arrays, because 'vec_basis' only has the optimal pre-computed ratio K/P = B_opt
matrix_acc <- arr_acc[,,B_id]
tau_lam_Q <- 0.01
n_acceptable <- 25  # maximum number of models in the acceptable region
n_ensemble   <- 5   # maximum number of models in the ensemble (most SMOOTH from the models in the acceptable region)
if(n_ensemble > n_acceptable){ stop("'n_acceptable' must be larger or equal to 'n_ensemble'.") }
# compute acceptable region
if(L_model == "lm"){
stop("REVISE OPTIMAL REGION FORMULA + MULTIPLE MODELS NOT CODED YET.")
acceptable_region <- which( (matrix_acc - min(matrix_acc)) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA); colnames(acceptable_region) <- c("components","lambda","roughness")
}else if (L_model == "glm"){
acceptable_region <- which( (max(matrix_acc) - matrix_acc) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA,NA); colnames(acceptable_region) <- c("components","lambda","roughness","acc")
}
for(q in 1:nr){
acceptable_region[q,"roughness"] <- arr_roughStd[acceptable_region[q,"components"], acceptable_region[q,"lambda"], B_id]
acceptable_region[q,"acc"] <- matrix_acc[acceptable_region[q,"components"], acceptable_region[q,"lambda"]]
}
# order by 'acc' and select top 'n_acceptable'
acceptable_region <- acceptable_region[order(acceptable_region[,"acc"], decreasing=T),]
if(nrow(acceptable_region) > n_acceptable){ acceptable_region <- acceptable_region[1:n_acceptable,] # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_acceptable'
}else{                                      n_acceptable <- nrow(acceptable_region) }
if(n_acceptable < n_ensemble){ n_ensemble <- n_acceptable } # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_ensemble'
# re-order by increasing roughness
acceptable_region <- acceptable_region[order(acceptable_region[,"roughness"]),]
# select best models
best_combo_IDs <- acceptable_region[, c("components","lambda")]
best_combo <- cbind(vec_components[best_combo_IDs[,"components"]], vec_lambdas[best_combo_IDs[,"lambda"]]); colnames(best_combo) <- c("Q_opt", "lam_opt")
#---# Levelplot for accuracy and roughness
brewer.div <- colorRampPalette(brewer.pal(11, "Spectral"), interpolate = "spline")
precision <- 3  # decimal places
plotMe_acc <- round(arr_acc[,,B_id], precision); rownames(plotMe_acc) <- vec_components; colnames(plotMe_acc) <- round(vec_lambdas,2)
plotMe_rough <- arr_roughStd[,,B_id]; rownames(plotMe_rough) <- vec_components; colnames(plotMe_rough) <- round(vec_lambdas,2)
# accuracy plot
# pdf(file = paste0(loc_figures, "fig_MAP_accuracy2.pdf"), height=5, width=5, pointsize=12)
colors_at <- seq(floor((10^precision)*min(plotMe_acc))/(10^precision), ceiling((10^precision)*max(plotMe_acc))/(10^precision), len=16)
the_labels <- round(colors_at,3);   the_labels[c(2,3,5,6,8,9,11,12,14,15)] <- ""
levelplot(plotMe_acc, at=colors_at, panel=crossvalidation_levelplot, letter=list(char="a", xloc=1, yloc=ncol(plotMe_acc)), col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="AUC map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
vec_components
# write package documentation
setwd("~/Dropbox/research/projects/nirs/mlevcm/")
document()
?fdaML_train
library(mlevcm)
# write package documentation
setwd("~/Dropbox/research/projects/nirs/mlevcm/")
document()
?dataSplit
document()
?dataSplit
library(mlevcm)
?dataSplit
document()
?dataSplit
document()
?fdaML_train
