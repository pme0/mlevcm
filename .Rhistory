#---# Determine parameter region for ensemble meodel
B_id <- 1 # this is the first (and only) element of 'arr_acc' and similar arrays, because 'vec_basis' only has the optimal pre-computed ratio K/P = B_opt
matrix_acc <- arr_acc[,,B_id]
tau_lam_Q <- 0.01
n_acceptable <- 25  # maximum number of models in the acceptable region
n_ensemble   <- 5   # maximum number of models in the ensemble (most SMOOTH from the models in the acceptable region)
if(n_ensemble > n_acceptable){ stop("'n_acceptable' must be larger or equal to 'n_ensemble'.") }
# compute acceptable region
if(L_model == "lm"){
stop("REVISE OPTIMAL REGION FORMULA + MULTIPLE MODELS NOT CODED YET.")
acceptable_region <- which( (matrix_acc - min(matrix_acc)) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA); colnames(acceptable_region) <- c("components","lambda","roughness")
}else if (L_model == "glm"){
acceptable_region <- which( (max(matrix_acc) - matrix_acc) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA,NA); colnames(acceptable_region) <- c("components","lambda","roughness","acc")
}
for(q in 1:nr){
acceptable_region[q,"roughness"] <- arr_roughStd[acceptable_region[q,"components"], acceptable_region[q,"lambda"], B_id]
acceptable_region[q,"acc"] <- matrix_acc[acceptable_region[q,"components"], acceptable_region[q,"lambda"]]
}
# order by 'acc' and select top 'n_acceptable'
acceptable_region <- acceptable_region[order(acceptable_region[,"acc"], decreasing=T),]
if(nrow(acceptable_region) > n_acceptable){ acceptable_region <- acceptable_region[1:n_acceptable,] # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_acceptable'
}else{                                      n_acceptable <- nrow(acceptable_region) }
if(n_acceptable < n_ensemble){ n_ensemble <- n_acceptable } # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_ensemble'
# re-order by increasing roughness
acceptable_region <- acceptable_region[order(acceptable_region[,"roughness"]),]
# select best models
best_combo_IDs <- acceptable_region[, c("components","lambda")]
best_combo <- cbind(vec_components[best_combo_IDs[,"components"]], vec_lambdas[best_combo_IDs[,"lambda"]]); colnames(best_combo) <- c("Q_opt", "lam_opt")
#---# Levelplot for accuracy and roughness
brewer.div <- colorRampPalette(brewer.pal(11, "Spectral"), interpolate = "spline")
precision <- 3  # decimal places
plotMe_acc <- round(arr_acc[,,B_id], precision); rownames(plotMe_acc) <- vec_components; colnames(plotMe_acc) <- round(vec_lambdas,2)
plotMe_rough <- arr_roughStd[,,B_id]; rownames(plotMe_rough) <- vec_components; colnames(plotMe_rough) <- round(vec_lambdas,2)
# accuracy plot
# pdf(file = paste0(loc_figures, "fig_MAP_accuracy2.pdf"), height=5, width=5, pointsize=12)
colors_at <- seq(floor((10^precision)*min(plotMe_acc))/(10^precision), ceiling((10^precision)*max(plotMe_acc))/(10^precision), len=16)
the_labels <- round(colors_at,3);   the_labels[c(2,3,5,6,8,9,11,12,14,15)] <- ""
levelplot(plotMe_acc, at=colors_at, panel=annotated_levelplot, letter="a", col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="AUC map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
# roughness plot
# pdf(file = paste0(loc_figures, "fig_MAP_roughness2.pdf", height=5, width=5, pointsize=12)
colors_at <- exp(seq(log(min(plotMe_rough)*0.95), log(max(plotMe_rough)*1.05), len=16))
the_labels <- round(colors_at,2);   the_labels[c(2,3,4,5,6,7,8,10,12)] <- ""
levelplot(plotMe_rough, at=colors_at, panel=annotated_levelplot, letter="b", col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="ROUGHNESS map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
if( !(max(matrix_acc) - matrix_acc[best_combo_IDs[1,"components"], best_combo_IDs[1,"lambda"]] <= tau_lam_Q) ){ stop("Closeness criterion not satisfied!") }   # check that the result satisfies the criterion
#---# Test optimal and sub-optimal
cat("",paste0("Parameter set ",(iii+1),"/",n_modelTypes, " (vr=", L_reduction, ",vs=", ifelse(L_smooth==T,"T","F"), ",vf=", ifelse(L_functional==T,"T","F") ,") | COMPUTING OPTIMAL AND SUBOPTIMAL MODELS:"), sep="\n")
pb_subopt = txtProgressBar(min = 0, max = n_ensemble+1, initial = 0, style = 3)
set.seed(17571);  obj_std <- fdaML(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth=F, intercept=T, lam_cv_type="n", lam_vec="default", reps=N_reps, Q_len=NULL, Q_opt=NULL, Q_vec=NULL, split_size=0.5, Q_opt_threshold=0.01, balanced=F, weighted=F, weights=NULL, Bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=F))
setTxtProgressBar(pb_subopt, 1)
suboptimal_MODELS <- list(); suboptimal_RES <- matrix(NA, n_ensemble, 8); colnames(suboptimal_RES) <- c("Q", "R", "lam", "acc", "err_cv", "err_cv_stdev", "err_alt", "err_alt_stdev")
for(jj in 1:n_ensemble){
set.seed(17571);  obj_opt <- fdaML(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth=F, intercept=T, lam_cv_type="ocv", lam_vec=best_combo[jj,"lam_opt"], reps=N_reps, Q_len=NULL, Q_opt=best_combo[jj,"Q_opt"], Q_vec=NULL, split_size=0.5, Q_opt_threshold=0.01, balanced=F, weighted=F, weights=NULL, Bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=F))
suboptimal_RES[jj,"Q"] <- obj_opt$Q_opt
suboptimal_RES[jj,"R"] <- GET_roughness(rowMeans(obj_opt$beta), std=T)
suboptimal_RES[jj,"lam"] <- obj_opt$lam_opt
suboptimal_RES[jj,"acc"] <- mean(obj_opt$AUC_opt[,"test"])
suboptimal_RES[jj,"err_cv"] <- fdaPlot(obj_opt)$err
suboptimal_RES[jj,"err_cv_stdev"] <- fdaPlot(obj_opt)$err_stdev
suboptimal_MODELS[[jj]] <- obj_opt
setTxtProgressBar(pb_subopt, jj+1)
}
# fdaPlot(obj_std, hist_range=c(-20,20))
# fdaPlot(obj_opt)
#{"Q","R","lambda","acc"}
if(L_model == "lm"){
stop("NOT CODED YET! calls 'obj_std$AUC_opt' but that only works for GLM.")
}else if(L_model == "glm"){
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"GLM"),  c("Q","R","lambda","acc","err_cv_smoothest","err_cv_stdev_smoothest")] <- c(obj_std$Q_opt, GET_roughness(rowMeans(obj_std$beta), std=T), obj_std$lam_opt, mean(obj_std$AUC_opt[,"test"]), fdaPlot(obj_std)$err, fdaPlot(obj_std)$err_stdev) # for the non-penalised model, we record the error in the 'smoothest' column, although there's only one model here (lambda=0)
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("Q","R","lambda","acc","err_cv_smoothest","err_cv_stdev_smoothest","err_cv_ensemble","err_cv_stdev_ensemble")] <- c(mean(suboptimal_RES[,"Q"]), mean(suboptimal_RES[,"R"]), mean(suboptimal_RES[,"lam"]), mean(suboptimal_RES[,"acc"]), unname(suboptimal_RES[1,"err_cv"]), unname(suboptimal_RES[1,"err_cv_stdev"]), mean(suboptimal_RES[,"err_cv"]), mean(suboptimal_RES[,"err_cv_stdev"]))
}
#---# P-values for non-functional variable
# ii_Zpvalues <- (raw_data[,"Species"] %in% SPE) & (raw_data[,"Location"] %in% c(LOC_train,LOC_test)) & (raw_data[,"Generation"] %in% GEN_train)
# balanced_classes <- T
# set.seed(17571);  obj_Zpvalues <- fdaML(ll = list(X=X[ii_Zpvalues,], y=factor(y[ii_Zpvalues]), Z=matrix(as.numeric(raw_data[ii_Zpvalues,"Location",drop=F] == "Klesso"), sum(ii_Zpvalues), 1), task=L_task, model=L_model, reduction=L_reduction, smooth=F, intercept=T, lam_cv_type="n", lam_vec="default", reps=N_reps, Q_len=NULL, Q_opt=NULL, Q_vec=NULL, split_size=0.5, Q_opt_threshold=0.01, balanced=balanced_classes, weighted=F, weights=NULL, Bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=T))
# plot(obj_Zpvalues$Z_pvalue);  abline(h=0.05, lwd=2);  legend("topright", legend=paste0("median p-value = ", round(median(obj_Zpvalues$Z_pvalue),3)), bty="n", cex=0.9)
#---# Test with alternative dataset
#ii <- (raw_data[,"Feeding_status"] == "Exposed") & (raw_data[,"Infection_status"] %in% c("infectious","uninfectious")) & (raw_data[,"Scanning_day"] %in% c(17,19))
#X_subset_alt <- X[ii,];  y_subset_alt <- rep(0, sum(ii));  y_subset_alt[y[ii] == "infectious"] <- 1;
#
if(DATA_TYPE == "species_A1T1"){
# test with alternative dataset (species_A1T1)
GEN_test <- c("F0", "F1")
ii <- (raw_data[,"Species"] %in% SPE) & (raw_data[,"Location"] %in% LOC_test) & (raw_data[,"Generation"] %in% GEN_train)
X_subset_alt <- X[ii,];  y_subset_alt <- rep(0, sum(ii));  y_subset_alt[raw_data[ii,"Species"] == SPE[1]] <- 1
}else if(DATA_TYPE == "age"){
# test with alternative dataset (age)
ii <- (raw_data[,"Species"] %in% c("gambiae"))
X_subset_alt <- X[ii,];  y_subset_alt <- y[ii]
locTest <- "--"
}else{
stop("'DATA_TYPE' invalid.")
}
cat("",paste0("Parameter set ",(iii+1),"/", n_modelTypes, " (vr=", L_reduction, ",vs=", ifelse(L_smooth==T,"T","F"), ",vf=", ifelse(L_functional==T,"T","F") ,") | TESTING ALTERNATIVE DATASET:"), sep="\n")
pb_alt = txtProgressBar(min = 0, max = n_ensemble+1, initial = 0, style = 3)
set.seed(17571);  obj_alt_penNOP <- fdaMLpred(obj = obj_std, new_x = X_subset_alt, new_y = y_subset_alt, verbose=F)
setTxtProgressBar(pb_alt, 1)
# obj_alt_penNOP$errorBreakdown   # confusion matrix
alternative_MODELS <- list()
for(jj in 1:n_ensemble){
set.seed(17571);  obj_alt_penYEP <- fdaMLpred(obj = suboptimal_MODELS[[jj]], new_x = X_subset_alt, new_y = y_subset_alt, verbose=F)
# obj_alt_penYEP$errorBreakdown   # confusion matrix
#alternative_MODELS[[jj]] <- alternativeMODELS
suboptimal_RES[jj,"err_alt"] <- obj_alt_penYEP$avgTestErr
suboptimal_RES[jj,"err_alt_stdev"] <- obj_alt_penYEP$stdevTestErr
setTxtProgressBar(pb_alt, jj+1)
}
# re-order by increasing roughness
#suboptimal_RES <- suboptimal_RES[order(suboptimal_RES[,"R"]),]
write.table(x = round(suboptimal_RES, 8), file = paste0(loc_data, DATA_TYPE, "_suboptimalRESULTS_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), "p", toupper(L_model) ,"_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
#fdaPlot(obj_alt_penNOP)
#fdaPlot(obj_alt_penYEP)
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""), "GLM"), c("err_alt_smoothest", "err_alt_stdev_smoothest")] <- c(obj_alt_penNOP$avgTestErr, obj_alt_penNOP$stdevTestErr) # for the non-penalised model, we record the error in the 'smoothest' column, although there's only one model here (lambda=0)
#ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("err_alt", "err_alt_stdev")] <- c(obj_alt_penYEP$avgTestErr, obj_alt_penYEP$stdevTestErr)
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("err_alt_smoothest", "err_alt_stdev_smoothest", "err_alt_ensemble", "err_alt_stdev_ensemble")] <- c(suboptimal_RES[1,"err_alt"], suboptimal_RES[1,"err_alt_stdev"], mean(suboptimal_RES[,"err_alt"]), mean(suboptimal_RES[jj,"err_alt_stdev"]))
#---# save summary results
iii <- iii + 1
if(DATA_TYPE == "species_A1T1"){
#saveRDS(ALL_RES, file=paste0(loc_data, DATA_TYPE,"_RESULTS__GLM_",toupper(L_reduction), "_", get_fname(SPE,"spe"), "_TrainOn_", LOC_train, get_fname(GEN_train,"gen"),"_TestOn_", LOC_test, get_fname(GEN_test,"gen"), "__iii-", iii, ".Rdata"))
write.table(x = round(ALL_RES,8), file = paste0(loc_data, DATA_TYPE,"_summaryRESULTS_", toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
}else if(DATA_TYPE == "age"){
write.table(x = round(ALL_RES,8), file = paste0(loc_data, DATA_TYPE,"_summaryRESULTS_", toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
}else{
stop("'DATA_TYPE' invalid.")
}
end_time <- Sys.time()
cat("", paste0("cumulative time = ", round(end_time - start_time, 2), " ", attr(end_time - start_time, "units")), sep="\n")
# loaded_RES <- readRDS(loc_data, "species_A1T1_RESULTS__GLM_PLS_arabVSgamb_TrainOn_LongoF0F1_TestOn_KlessoF0F1.RData")
}#vf
}#vs
}#vr
B_id <- 1 # this is the first (and only) element of 'arr_acc' and similar arrays, because 'vec_basis' only has the optimal pre-computed ratio K/P = B_opt
matrix_acc <- arr_acc[,,B_id]
tau_lam_Q <- 0.01
n_acceptable <- 25  # maximum number of models in the acceptable region
n_ensemble   <- 5   # maximum number of models in the ensemble (most SMOOTH from the models in the acceptable region)
if(n_ensemble > n_acceptable){ stop("'n_acceptable' must be larger or equal to 'n_ensemble'.") }
# compute acceptable region
if(L_model == "lm"){
stop("REVISE OPTIMAL REGION FORMULA + MULTIPLE MODELS NOT CODED YET.")
acceptable_region <- which( (matrix_acc - min(matrix_acc)) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA); colnames(acceptable_region) <- c("components","lambda","roughness")
}else if (L_model == "glm"){
acceptable_region <- which( (max(matrix_acc) - matrix_acc) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA,NA); colnames(acceptable_region) <- c("components","lambda","roughness","acc")
}
for(q in 1:nr){
acceptable_region[q,"roughness"] <- arr_roughStd[acceptable_region[q,"components"], acceptable_region[q,"lambda"], B_id]
acceptable_region[q,"acc"] <- matrix_acc[acceptable_region[q,"components"], acceptable_region[q,"lambda"]]
}
# order by 'acc' and select top 'n_acceptable'
acceptable_region <- acceptable_region[order(acceptable_region[,"acc"], decreasing=T),]
if(nrow(acceptable_region) > n_acceptable){ acceptable_region <- acceptable_region[1:n_acceptable,] # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_acceptable'
}else{                                      n_acceptable <- nrow(acceptable_region) }
if(n_acceptable < n_ensemble){ n_ensemble <- n_acceptable } # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_ensemble'
# re-order by increasing roughness
acceptable_region <- acceptable_region[order(acceptable_region[,"roughness"]),]
# select best models
best_combo_IDs <- acceptable_region[, c("components","lambda")]
best_combo <- cbind(vec_components[best_combo_IDs[,"components"]], vec_lambdas[best_combo_IDs[,"lambda"]]); colnames(best_combo) <- c("Q_opt", "lam_opt")
#---# Levelplot for accuracy and roughness
brewer.div <- colorRampPalette(brewer.pal(11, "Spectral"), interpolate = "spline")
precision <- 3  # decimal places
plotMe_acc <- round(arr_acc[,,B_id], precision); rownames(plotMe_acc) <- vec_components; colnames(plotMe_acc) <- round(vec_lambdas,2)
plotMe_rough <- arr_roughStd[,,B_id]; rownames(plotMe_rough) <- vec_components; colnames(plotMe_rough) <- round(vec_lambdas,2)
# accuracy plot
# pdf(file = paste0(loc_figures, "fig_MAP_accuracy2.pdf"), height=5, width=5, pointsize=12)
colors_at <- seq(floor((10^precision)*min(plotMe_acc))/(10^precision), ceiling((10^precision)*max(plotMe_acc))/(10^precision), len=16)
the_labels <- round(colors_at,3);   the_labels[c(2,3,5,6,8,9,11,12,14,15)] <- ""
levelplot(plotMe_acc, at=colors_at, panel=annotated_levelplot, letter="a", col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="AUC map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
colors_at <- exp(seq(log(min(plotMe_rough)*0.95), log(max(plotMe_rough)*1.05), len=16))
the_labels <- round(colors_at,2);   the_labels[c(2,3,4,5,6,7,8,10,12)] <- ""
levelplot(plotMe_rough, at=colors_at, panel=annotated_levelplot, letter="b", col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="ROUGHNESS map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
if( !(max(matrix_acc) - matrix_acc[best_combo_IDs[1,"components"], best_combo_IDs[1,"lambda"]] <= tau_lam_Q) ){ stop("Closeness criterion not satisfied!") }   # check that the result satisfies the criterion
cat("",paste0("Parameter set ",(iii+1),"/",n_modelTypes, " (vr=", L_reduction, ",vs=", ifelse(L_smooth==T,"T","F"), ",vf=", ifelse(L_functional==T,"T","F") ,") | COMPUTING OPTIMAL AND SUBOPTIMAL MODELS:"), sep="\n")
pb_subopt = txtProgressBar(min = 0, max = n_ensemble+1, initial = 0, style = 3)
set.seed(17571);  obj_std <- fdaML(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth=F, intercept=T, lam_cv_type="n", lam_vec=NULL, reps=N_reps, Q_len=NULL, Q_opt=NULL, Q_vec=NULL, split_size=0.5, Q_opt_threshold=0.01, balanced=F, weighted=F, weights=NULL, Bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=F))
setTxtProgressBar(pb_subopt, 1)
suboptimal_MODELS <- list(); suboptimal_RES <- matrix(NA, n_ensemble, 8); colnames(suboptimal_RES) <- c("Q", "R", "lam", "acc", "err_cv", "err_cv_stdev", "err_alt", "err_alt_stdev")
for(jj in 1:n_ensemble){
set.seed(17571);  obj_opt <- fdaML(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth=F, intercept=T, lam_cv_type="ocv", lam_vec=best_combo[jj,"lam_opt"], reps=N_reps, Q_len=NULL, Q_opt=best_combo[jj,"Q_opt"], Q_vec=NULL, split_size=0.5, Q_opt_threshold=0.01, balanced=F, weighted=F, weights=NULL, Bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=F))
suboptimal_RES[jj,"Q"] <- obj_opt$Q_opt
suboptimal_RES[jj,"R"] <- GET_roughness(rowMeans(obj_opt$beta), std=T)
suboptimal_RES[jj,"lam"] <- obj_opt$lam_opt
suboptimal_RES[jj,"acc"] <- mean(obj_opt$AUC_opt[,"test"])
suboptimal_RES[jj,"err_cv"] <- fdaPlot(obj_opt)$err
suboptimal_RES[jj,"err_cv_stdev"] <- fdaPlot(obj_opt)$err_stdev
suboptimal_MODELS[[jj]] <- obj_opt
setTxtProgressBar(pb_subopt, jj+1)
}
if(L_model == "lm"){
stop("NOT CODED YET! calls 'obj_std$AUC_opt' but that only works for GLM.")
}else if(L_model == "glm"){
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"GLM"),  c("Q","R","lambda","acc","err_cv_smoothest","err_cv_stdev_smoothest")] <- c(obj_std$Q_opt, GET_roughness(rowMeans(obj_std$beta), std=T), obj_std$lam_opt, mean(obj_std$AUC_opt[,"test"]), fdaPlot(obj_std)$err, fdaPlot(obj_std)$err_stdev) # for the non-penalised model, we record the error in the 'smoothest' column, although there's only one model here (lambda=0)
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("Q","R","lambda","acc","err_cv_smoothest","err_cv_stdev_smoothest","err_cv_ensemble","err_cv_stdev_ensemble")] <- c(mean(suboptimal_RES[,"Q"]), mean(suboptimal_RES[,"R"]), mean(suboptimal_RES[,"lam"]), mean(suboptimal_RES[,"acc"]), unname(suboptimal_RES[1,"err_cv"]), unname(suboptimal_RES[1,"err_cv_stdev"]), mean(suboptimal_RES[,"err_cv"]), mean(suboptimal_RES[,"err_cv_stdev"]))
}
if(DATA_TYPE == "species_A1T1"){
# test with alternative dataset (species_A1T1)
GEN_test <- c("F0", "F1")
ii <- (raw_data[,"Species"] %in% SPE) & (raw_data[,"Location"] %in% LOC_test) & (raw_data[,"Generation"] %in% GEN_train)
X_subset_alt <- X[ii,];  y_subset_alt <- rep(0, sum(ii));  y_subset_alt[raw_data[ii,"Species"] == SPE[1]] <- 1
}else if(DATA_TYPE == "age"){
# test with alternative dataset (age)
ii <- (raw_data[,"Species"] %in% c("gambiae"))
X_subset_alt <- X[ii,];  y_subset_alt <- y[ii]
locTest <- "--"
}else{
stop("'DATA_TYPE' invalid.")
}
cat("",paste0("Parameter set ",(iii+1),"/", n_modelTypes, " (vr=", L_reduction, ",vs=", ifelse(L_smooth==T,"T","F"), ",vf=", ifelse(L_functional==T,"T","F") ,") | TESTING ALTERNATIVE DATASET:"), sep="\n")
pb_alt = txtProgressBar(min = 0, max = n_ensemble+1, initial = 0, style = 3)
set.seed(17571);  obj_alt_penNOP <- fdaMLpred(obj = obj_std, new_x = X_subset_alt, new_y = y_subset_alt, verbose=F)
setTxtProgressBar(pb_alt, 1)
# obj_alt_penNOP$errorBreakdown   # confusion matrix
alternative_MODELS <- list()
for(jj in 1:n_ensemble){
set.seed(17571);  obj_alt_penYEP <- fdaMLpred(obj = suboptimal_MODELS[[jj]], new_x = X_subset_alt, new_y = y_subset_alt, verbose=F)
# obj_alt_penYEP$errorBreakdown   # confusion matrix
#alternative_MODELS[[jj]] <- alternativeMODELS
suboptimal_RES[jj,"err_alt"] <- obj_alt_penYEP$avgTestErr
suboptimal_RES[jj,"err_alt_stdev"] <- obj_alt_penYEP$stdevTestErr
setTxtProgressBar(pb_alt, jj+1)
}
write.table(x = round(suboptimal_RES, 8), file = paste0(loc_data, DATA_TYPE, "_suboptimalRESULTS_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), "p", toupper(L_model) ,"_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
#fdaPlot(obj_alt_penNOP)
#fdaPlot(obj_alt_penYEP)
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""), "GLM"), c("err_alt_smoothest", "err_alt_stdev_smoothest")] <- c(obj_alt_penNOP$avgTestErr, obj_alt_penNOP$stdevTestErr) # for the non-penalised model, we record the error in the 'smoothest' column, although there's only one model here (lambda=0)
#ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("err_alt", "err_alt_stdev")] <- c(obj_alt_penYEP$avgTestErr, obj_alt_penYEP$stdevTestErr)
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("err_alt_smoothest", "err_alt_stdev_smoothest", "err_alt_ensemble", "err_alt_stdev_ensemble")] <- c(suboptimal_RES[1,"err_alt"], suboptimal_RES[1,"err_alt_stdev"], mean(suboptimal_RES[,"err_alt"]), mean(suboptimal_RES[jj,"err_alt_stdev"]))
ALL_RES
iii <- iii + 1
if(DATA_TYPE == "species_A1T1"){
#saveRDS(ALL_RES, file=paste0(loc_data, DATA_TYPE,"_RESULTS__GLM_",toupper(L_reduction), "_", get_fname(SPE,"spe"), "_TrainOn_", LOC_train, get_fname(GEN_train,"gen"),"_TestOn_", LOC_test, get_fname(GEN_test,"gen"), "__iii-", iii, ".Rdata"))
write.table(x = round(ALL_RES,8), file = paste0(loc_data, DATA_TYPE,"_summaryRESULTS_", toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
}else if(DATA_TYPE == "age"){
write.table(x = round(ALL_RES,8), file = paste0(loc_data, DATA_TYPE,"_summaryRESULTS_", toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
}else{
stop("'DATA_TYPE' invalid.")
}
# write package documentation
setwd("~/Dropbox/research/projects/nirs/mlevcm/")
library(mlevcm)
# write package documentation
setwd("~/Dropbox/research/projects/nirs/mlevcm/")
document()
?fdaML
?fdaML_train
?fdaML_predict
library(mlevcm)
?fdaML_predict
# write package documentation
setwd("~/Dropbox/research/projects/nirs/mlevcm/")
document()
library(mlevcm)
?fdaML_train
library("devtools")
library(roxygen2)
# write package documentation
setwd("~/Dropbox/research/projects/nirs/mlevcm/")
document()
Params <- list(dataset_name="B_A1T1", y_bin=F, avg_replics=T, Xsmooth=F)
if(Params$avg_replics){
Params$tp <- list(A1 = 1:3,
A2 = 1:4,
A3 = 1:2,
A4 = 1:4,
B_A1T1 = 1:4,                # Burkina Faso experiments, activity 1 test 1 (species/locations/generations)
B_A1E1 = 1:2,                # Burkina Faso experiments, activity 1 experient 1 (age comparison)
B_A2T2 = 1:4,                # Burkina Faso experiments, activity 2 test 2 updated (infection)
B_A2E2 = 1:4,                # Burkina Faso experiments, activity 2 experient 2 (infection)
B_A4E4 = 1:4)                # Burkina Faso experiments, activity 4 experient 4 (infection, timepoint 1)
}else{
Params$tp <- list(A1 = 1,
A2 = 1,
A3 = 1,
A4 = 1,
B_A2T2 = 1,
B_A2E2 = 1,
B_A1T1 = 1,
B_A1E1 = 1,
B_A4E4 = 1)
}
load_A1 <- function(Params){
# read data
data_A1 <-  read.table(file = "~/Dropbox/research/projects/nirs/data/datasets/experiments_2017_SouthKensington/A1_sporozoites/A1_sporozoites_01-06-2017_y.txt", header=T, na.strings = "NA")
target_pos <- Params$tp$A1  # {1,2,3}
select <- (!is.na(data_A1[,"Position"])) & (!is.na(data_A1[,"Sporozoites"])) & (data_A1[,"Position"] %in% target_pos)
#select[153:154] <- FALSE # outliers, etc.
# indices of repetitions for each mosquito
idx_A1 <- list()
for(i in unique(data_A1[select,"Mosquito_ID"])){
rng <- which(data_A1[,"Mosquito_ID"] == i)   #which((data_A1[,"Mosquito_ID"])[data_A1[,"Mosquito_ID"] == i])
aux <- (data_A1[rng,"Position"] %in% target_pos) & !is.na(data_A1[rng,"Position"]) & !is.na(data_A1[rng,"Sporozoites"])
idx_A1[[i]] <- rng[aux]
}
n_replics <- unlist(lapply(idx_A1, length))  # store how many repeated observations for each specimen
# read predictor (X)
nx <- 212  # number of spectra files
dx <- matrix(0, nx, 2151)
f_base <- "~/Dropbox/research/projects/nirs/data/datasets/experiments_2017_SouthKensington/A1_sporozoites/AnS_sporo_"
for(k in 1:nx){
f_name <- paste(f_base, formatC(k, width = 5,flag = 0),".txt", sep="")
fk <- read.table(file = f_name)
dx[k,] <- fk$V1
}
# average replications
if(Params$avg_replics){
data_X <- c()
for(i in unique(data_A1[select,"Mosquito_ID"])){
if(length(idx_A1[[i]]) > 1){
data_X <- rbind(data_X, colMeans(dx[idx_A1[[i]],]))
}else{
data_X <- rbind(data_X, dx[idx_A1[[i]],])
}
}
}else{
data_X <- dx[select,]
}
# read response (y)
i_y <- select & ((1:nrow(data_A1)) %in% unlist(sapply(idx_A1, "[[", 1)))
data_y <- data_A1[i_y,"Sporozoites"]
return(list(X = data_X, y = data_y, n_replics = n_replics[n_replics != 0], raw_data = data_A1[i_y,]))
# re-save with simple layout
#data_export <- data.frame(y = y, X = X)
#write.table(data_export, file="~/Dropbox/research/projects/nirs/data/datasets/experiments_Tom/A1_sporozoites/DATASET_sporozoites_2017_06_01.txt", sep=",", row.names=F, col.names=T)
}#load_A1
load_A2 <- function(Params){
# read response (y)
data_A2 <-  read.table(file = "~/Dropbox/research/projects/nirs/data/datasets/experiments_2017_SouthKensington/A2_oocysts/Notes_oocysts_2017_06_05_y.txt", header=T, na.strings = "NA")
target_pos <- Params$tp$A2  # {1,2,3,4}
select <- (!is.na(data_A2[,"Mosquito_ID"])) & (!is.na(data_A2[,"Position"])) & (!is.na(data_A2[,"Oocysts"])) & (data_A2[,"Position"] %in% target_pos)
#select <- data_A2[,2] == target_pos & !is.na(data_A2[,1]) & !is.na(data_A2[,2]) & !is.na(data_A2[,3]) & !is.na(data_A2[,4])
if(!is.na(which(data_A2[,"Mosquito_ID"]==39 & (data_A2[,"Position"] %in% target_pos))[2])) select[which(data_A2[,"Mosquito_ID"]==39 & (data_A2[,"Position"] %in% target_pos))[2]] <- F  # repeated position, see xlsx notes
data_y <- data_A2[select,4]
# indices of repetitions for each mosquito
idx_A2 <- list()
for(i in unique(data_A2[select,"Mosquito_ID"])){
rng <- which(data_A2[,"Mosquito_ID"] == i)
aux <- (data_A2[rng,"Position"] %in% target_pos) & !is.na(data_A2[rng,"Position"]) & !is.na(data_A2[rng,"Oocysts"])
idx_A2[[i]] <- rng[aux]
}
n_replics <- unlist(lapply(idx_A2, length))  # store how many repeated observations for each specimen
# read predictor (X)
nx <- 335  # number of spectra files
dx <- matrix(0, nx, 2151)
f_base <- "~/Dropbox/research/projects/nirs/data/datasets/experiments_2017_SouthKensington/A2_oocysts/AnS_oocysts_"
for(k in 1:nx){
f_name <- paste(f_base, formatC(k, width = 5,flag = 0),".txt", sep="")
fk <- read.table(file = f_name)
dx[k,] <- fk$V1
}
data_X <- dx[select,]
# average replications
# if(Params$avg_replics){
#   data_X <- c()
#   for(i in unique(data_A2[select,"Mosquito_ID"])){
#     if(length(idx_A2[[i]]) > 1){
#       data_X <- rbind(data_X, colMeans(dx[idx_A2[[i]],]))
#     }else{
#       data_X <- rbind(data_X, dx[idx_A2[[i]],])
#     }
#   }
# }else{
#   data_X <- dx[select,]
# }
# read response (y)
i_y <- select & ((1:nrow(data_A2)) %in% unlist(sapply(idx_A2, "[[", 1)))
data_y <- data_A2[i_y,"Oocysts"]
return(list(X = data_X, y = data_y, n_replics = n_replics[n_replics != 0], raw_data = data_A2[i_y,]))
}#load_A2
load_A3 <- function(Params){
# read data
data_A3 <-  read.table(file = "~/Dropbox/research/projects/nirs/data/datasets/experiments_2017_SouthKensington/A3_sporozoites/A3_sporozoites_29-06-2017_y.txt", header=T, na.strings = "NA")
target_pos <- Params$tp$A3 #{1,2}
select <- (!is.na(data_A3[,"Position"])) & (!is.na(data_A3[,"Sporozoites"])) & (data_A3[,"Position"] %in% target_pos)
select[139:150] <- FALSE # data recording error
select[153:154] <- FALSE # spectra 154 is an outlier [eliminate all replications to make averaging replicates easier]
# indices of repetitions for each mosquito
idx_A3 <- list()
for(i in unique(data_A3[select,"Mosquito_ID"])){
rng <- which(data_A3[,"Mosquito_ID"] == i)
aux <- (data_A3[rng,"Position"] %in% target_pos) & !is.na(data_A3[rng,"Position"]) & !is.na(data_A3[rng,"Sporozoites"])
idx_A3[[i]] <- rng[aux]
}
n_replics <- unlist(lapply(idx_A3, length))  # store how many repeated observations for each specimen
# read predictor (X)
nx <- 180  # number of spectra files
dx <- matrix(0, nx, 2151)
f_base <- "~/Dropbox/research/projects/nirs/data/datasets/experiments_2017_SouthKensington/A3_sporozoites/sporozoites_29June2017_"
for(k in 1:nx){
f_name <- paste(f_base, formatC(k, width = 5,flag = 0),".txt", sep="")
fk <- read.table(file = f_name)
dx[k,] <- fk$V1
}
# average replications
if(Params$avg_replics){
data_X <- c()
for(i in unique(data_A3[select,"Mosquito_ID"])){
if(length(idx_A3[[i]]) > 1){
data_X <- rbind(data_X, colMeans(dx[idx_A3[[i]],]))
}else{
data_X <- rbind(data_X, dx[idx_A3[[i]],])
}
}
}else{
data_X <- dx[select,]
}
# read response (y)
i_y <- select & ((1:nrow(data_A3)) %in% unlist(sapply(idx_A3, "[[", 1)))
data_y <- data_A3[i_y,"Sporozoites"]
return(list(X = data_X, y = data_y, n_replics = n_replics[n_replics != 0], raw_data = data_A3[i_y,]))
}#load_A3
load_A4 <- function(Params){
# read data
data_A4 <-  read.table(file = "~/Dropbox/research/projects/nirs/data/datasets/experiments_2017_SouthKensington/A4_sporozoites/A4_sporozoites_19-07-2017_y.txt", header=T, na.strings = "NA")
data_A4 <- cbind(1:nrow(data_A4), data_A4); colnames(data_A4)[1] <- "Scan_ID"
target_pos <- Params$tp$A4 #{1,2,3,4}
select <- (!is.na(data_A4[,"Position"])) & (!is.na(data_A4[,"Sporozoites"])) & (data_A4[,"Position"] %in% target_pos) #& (!(1:nrow(data_A4) %in% 139:150))
#select[153:154] <- FALSE # outliers, recording errors, etc.
# indices of repetitions for each mosquito
idx_A4 <- list()
for(i in unique(data_A4[select,"Mosquito_ID"])){
rng <- which(data_A4[,"Mosquito_ID"] == i)
aux <- (data_A4[rng,"Position"] %in% target_pos) & !is.na(data_A4[rng,"Position"]) & !is.na(data_A4[rng,"Sporozoites"])
idx_A4[[i]] <- rng[aux]
}
n_replics <- unlist(lapply(idx_A4, length))  # store how many repeated observations for each specimen
# read spectra (X)
nx <- 328  # number of spectra files
dx <- matrix(0, nx, 2151)
f_base <- "~/Dropbox/research/projects/nirs/data/datasets/experiments_2017_SouthKensington/A4_sporozoites/sporozoites_19July2017_"
for(k in 1:nx){
f_name <- paste(f_base, formatC(k, width = 5,flag = 0),".txt", sep="")
fk <- read.table(file = f_name)
dx[k,] <- fk$V1
}
# average replications
if(Params$avg_replics){
data_X <- c()
for(i in unique(data_A4[select,"Mosquito_ID"])){
if(length(idx_A4[[i]]) > 1){
data_X <- rbind(data_X, colMeans(dx[idx_A4[[i]],]))
}else{
data_X <- rbind(data_X, dx[idx_A4[[i]],])
}
}
}else{
data_X <- dx[select,]
}
# read response (y)
i_y <- select & ((1:nrow(data_A4)) %in% unlist(sapply(idx_A4, "[[", 1)))
data_y <- data_A4[i_y,"Sporozoites"]
return(list(X = data_X, y = data_y, n_replics = n_replics[n_replics != 0], raw_data = data_A4[i_y,]))
}#load_A4
load_B_A1T1 <- function(Params){
# read data
#data <-  read.csv(file = "~/Dropbox/research/projects/nirs/data/datasets/Burkina NIRS Data/Activity 1 - Age/NIRS_E1T1_(PEDRO).csv", header=T, na.strings = "NA")
data <-  read.csv(file = "~/DROPBOX_overflow/research/projects/nirs/data/datasets/Burkina NIRS Data/Activity 1 - Age/NIRS_E1T1_(PEDRO).csv", header=T, na.strings = "NA")
target_pos <- Params$tp$B_A1T1  # {1,2,3,4}
select <- (!is.na(data[,"Position"])) & (!is.na(data[,"Age"])) & (!is.na(data[,"Location"])) & (!is.na(data[,"Generation"])) & (!is.na(data[,"Species"])) & (data[,"Position"] %in% target_pos)
#select[153:154] <- FALSE # outliers, etc.
unique_IDs <- unique(data[select,"Mosquito_ID"])
# indices of repetitions for each mosquito
idx <- list()
for(i in unique_IDs){
rng <- which(data[,"Mosquito_ID"] == i)   #which((data[,"Mosquito_ID"])[data[,"Mosquito_ID"] == i])
aux <- (data[rng,"Position"] %in% target_pos) & !is.na(data[rng,"Position"]) & !is.na(data[rng,"Age"]) & (!is.na(data[rng,"Location"])) & (!is.na(data[rng,"Generation"])) & (!is.na(data[rng,"Species"]))
idx[[i]] <- rng[aux]
}
n_replics <- unlist(lapply(idx, length))  # store how many repeated observations for each specimen
# read predictor (X)
dates    <- c("8Oct17","9Oct17","10Oct17")
nx_dates <- c(  695   ,  782   ,   1025  )
nx <- sum(nx_dates)  # number of spectra files
dx <- matrix(0, nx, 2151);  kk <- 0
for(day in dates){
for(k in 0:(nx_dates[which(dates == day)]-1)){
kk <- kk + 1
#f_name <- paste0("~/Dropbox/research/projects/nirs/data/datasets/Burkina NIRS Data/Activity 1 - Age/Test 1B/E1Test1_",day,"_", formatC(k, width = 5,flag = 0),".txt")
f_name <- paste0("~/DROPBOX_overflow/research/projects/nirs/data/datasets/Burkina NIRS Data/Activity 1 - Age/Test 1B/E1Test1_",day,"_", formatC(k, width = 5,flag = 0),".txt")
dx[kk,] <- read.table(file = f_name, header=T, sep="\t")[,2]
}
}
# average replications
if(Params$avg_replics){
data_X <- c()
for(i in unique_IDs){
if(length(idx[[i]]) > 1){
data_X <- rbind(data_X, colMeans(dx[idx[[i]],]))
}else{
data_X <- rbind(data_X, dx[idx[[i]],])
}
}
}else{
data_X <- dx[select,]
}
# read response (y)
i_y <- select & ((1:nrow(data)) %in% unlist(sapply(idx, "[[", 1)))
data_y <- factor(data[i_y,"Species"])
# raw data
raw_data <- data[i_y,]   #  table(raw_data[,c("Species","Location","Generation")])
return(list(X = data_X, y = data_y, n_replics = n_replics[n_replics != 0], raw_data = raw_data))
# re-save with simple layout
#data_export <- data.frame(y = y, X = X)
#write.table(data_export, file="~/Dropbox/research/projects/nirs/data/datasets/experiments_Tom/A1_sporozoites/DATASET_sporozoites_2017_06_01.txt", sep=",", row.names=F, col.names=T)
}#load_B_A1T1
#================================   B_A1T1  BURKINA FASO, ACTIVITY 1 EXPERIMENT 1 (AGE, test)
data_B_A1T1 <- load_B_A1T1(Params);   X <- data_B_A1T1$X;   y <- data_B_A1T1$y;   raw_data <- data_B_A1T1$raw_data
library(mlevcm)
balanced
best_combo_IDs[,"components"]
