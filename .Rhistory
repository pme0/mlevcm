}else if(DATA_TYPE == "species_???"){
;
}else if(DATA_TYPE == "age"){
SPE <- "COLU"   # species: {ARABvsGAMB , ARABvsCOLU , COLUvsGAMB}; age: {ARAB , GAMB , COLU}
ii <- (raw_data[,"Species"] == "coluzzii")
X_subset <- X[ii,];  y_subset <- y[ii]
L_task <- "regr"; L_model <- "lm"
}else{
stop("'DATA_TYPE' invalid.")
}
#
L_reduction <- vr
L_smooth <- vs
L_functional <- vf
# smooth here, so use 'smooth=F' in fdaML_train()
if(L_smooth){ X_subset <- fdaSmooth(X_subset) }
N <- ifelse( abs(nrow(X_subset)-length(y_subset)) == 0, nrow(X_subset), stop("'nrow(X)' different from 'length(y)'") );  P <- ncol(X_subset);  palette(rich.colors(length(unique(y_subset))))
# matplot(wvlenghts, t(X_subset), type="l", col=alpha(as.numeric(sum(y_subset==0)!=0)+y_subset,0.4), lty=1, ylim=c(0,2), xlab="wavelength", ylab="signal"); legend("topright", paste("y=",sort(unique(y_subset)),sep=""), horiz=T, lty=1, seg.len=0.8, col=1:length(unique(y_subset)), bty="n", cex=0.8)
########
################   OPTIMISE {# basis K}
########
if(L_functional){
B_opt <- 0.1
#   tau_K <- 0.01
#   vec_basis <- seq(0.1, 1, by=0.1); lb <- length(vec_basis)
#   acc_basis <- rep(NA, lb)
#   cat("",paste0("DETERMINING OPTIMAL FUNCTIONAL REPRESENTATION:"), sep="\n")
#   pb_fda = txtProgressBar(min = 0, max = lb, initial = 0, style = 3);
#   for(nb in 1:lb){
#     set.seed(17571);  obj <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth_w=NULL, intercept=T, lam_cv_type="n", lam_vec=NULL, reps=N_reps, Q_len=NULL, Q_opt=NULL, Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=F, estimation_w=NULL, bspline_dim=floor(vec_basis[nb] * ncol(X)), t_range=wvlenghts, verbose=F))
#     acc_basis[nb] <- mean(obj$perf_cv[,which(obj$Q_vec == obj$Q_opt)])
#     setTxtProgressBar(pb_fda, nb)
#   } # plot(vec_basis, acc_basis, type="l", ylim = c(0.99*min(acc_basis), max(acc_basis))); abline(h = max(acc_basis) - 0.01, col="blue")
#   B_opt <- vec_basis[which((max(acc_basis) - acc_basis) < tau_K)[1]]
}else{
B_opt <- 1
}
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"GLM"),  "K/P"] <- B_opt
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), "K/P"] <- B_opt
########
################   OPTIMISE {# components "Q", penalty parameter "lambda"}
########
#---# Cross-validate (Q,lambda)
vec_basis      <- seq(B_opt, B_opt, by=0.2); lb <- length(vec_basis)
paramsByModel <- list(pls = list(comp_p   = floor(seq(16, 40, len=10)), lam_p   = round(seq(0.5,   10,  len=10), 1),
comp_sp  = floor(seq(16, 30, len=10)), lam_sp  = round(seq(50,    100, len=10), 1),
comp_fp  = floor(seq(16, 30, len=10)), lam_fp  = round(seq(25,    100, len=10), 1),
comp_fsp = floor(seq(10, 30, len=10)), lam_fsp = round(seq(5,     150, len=10), 1)),
pca = list(comp_p   = floor(seq(30, 63, len=10)), lam_p   = round(seq(0.1,   7,   len=10), 1),  # Q=63 is the largest possible b/c of sample sizes
comp_sp  = floor(seq(16, 50, len=10)), lam_sp  = round(seq(0.1,   120, len=10), 1),
comp_fp  = floor(seq(10, 46, len=10)), lam_fp  = round(seq(0.01,  14,  len=10), 1),
comp_fsp = floor(seq(6,  50, len=10)), lam_fsp = round(seq(0.01,  14,  len=10), 1)))
vec_components <- paramsByModel[[L_reduction]][[paste0("comp_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), "p")]];  lc <- length(vec_components)
vec_lambdas    <- paramsByModel[[L_reduction]][[paste0("lam_",  ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), "p")]];  ll <- length(vec_lambdas)
arr_acc <- arr_acc_stdev <- array(NA, c(length(vec_components), length(vec_lambdas), length(vec_basis)), dimnames=list(paste0("c_",vec_components), paste0("l_",vec_lambdas), paste0("b_",vec_basis)))
arr_rough <- arr_roughStd <- arr_acc
if(L_load){ # load data
loadedData <- readRDS(file=paste0(loc_data, DATA_TYPE, "_CV_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"), ".Rdata"))
arr_acc <- loadedData$arr_acc;  arr_acc_stdev <- loadedData$arr_acc_stdev;  arr_rough <- loadedData$arr_rough;  arr_roughStd <- loadedData$arr_roughStd;  vec_basis <- loadedData$vec_basis;  vec_components <- loadedData$vec_components;  vec_lambdas <- loadedData$vec_lambdas
}else{
cat("",paste0("Parameter set ",(iii+1),"/", n_modelTypes, " (vr=", L_reduction, ",vs=", ifelse(L_smooth==T,"T","F"), ",vf=", ifelse(L_functional==T,"T","F") ,") | CROSS-VALIDATING Q/LAMBDA:"), sep="\n")
pb_cv = txtProgressBar(min = 0, max = lb*lc*ll, initial = 0, style = 3);   loopCounter <- 0
for(nb in 1:lb){
for(nc in 1:lc){
for(nl in 1:ll){
set.seed(17571);  obj <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth_w=NULL, intercept=T, lam_cv_type="ocv", lam_vec=vec_lambdas[nl], reps=N_reps, Q_len=NULL, Q_opt=vec_components[nc], Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=F, estimation_w=NULL, bspline_dim=floor(vec_basis[nb] * ncol(X)), t_range=wvlenghts, verbose=T))
arr_acc[nc,nl,nb] <- mean(obj$perf_cv[,which(obj$Q_vec == obj$Q_opt)])
arr_acc_stdev[nc,nl,nb] <- sd(obj$perf_cv[,which(obj$Q_vec == obj$Q_opt)])
arr_rough[nc,nl,nb] <- mean(obj$beta_roughness)
arr_roughStd[nc,nl,nb] <- mean(obj$beta_roughnessStd)
loopCounter <- loopCounter + 1;   setTxtProgressBar(pb_cv, loopCounter)
}
}
}
cv_list <- list(arr_acc = arr_acc,
arr_acc_stdev = arr_acc_stdev,
arr_rough = arr_rough,
arr_roughStd = arr_roughStd,
vec_basis = vec_basis,
vec_components = vec_components,
vec_lambdas = vec_lambdas)
saveRDS(cv_list, file=paste0(loc_data, DATA_TYPE,"_CV_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"), ".Rdata"))
}
#---# Diagnostic plots
# set.seed(17571);  obj_dgnostics <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth_w=NULL, intercept=T, lam_cv_type="n", lam_vec=NULL, reps=N_reps, Q_len=NULL, Q_opt=NULL, Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=F, estimation_w=NULL, bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=T))
# fdaPlot(obj_dgnostics)
#---# Determine best model (highest accuracy) - to be used in "obj_best" below
B_id <- 1 # this is the first (and only) element of 'arr_acc' and similar arrays, because 'vec_basis' only has the optimal pre-computed ratio K/P = B_opt
best_idx <- which(arr_acc[,,B_id] == max(arr_acc), arr.ind = TRUE)
best_components <- vec_components[best_idx[,'row']]
best_lambda <- vec_lambdas[best_idx[,'row']]
#---# Determine parameter region for ensemble meodel
matrix_acc <- arr_acc[,,B_id]
tau_lam_Q <- 0.01
n_acceptable <- 25  # maximum number of models in the acceptable region
n_ensemble   <- 5   # maximum number of models in the ensemble (most SMOOTH from the models in the acceptable region)
if(n_ensemble > n_acceptable){ stop("'n_acceptable' must be larger or equal to 'n_ensemble'.") }
# compute acceptable region
if(L_model == "lm"){
stop("REVISE OPTIMAL REGION FORMULA + MULTIPLE MODELS NOT CODED YET.")
acceptable_region <- which( (matrix_acc - min(matrix_acc)) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA); colnames(acceptable_region) <- c("components","lambda","roughness")
}else if (L_model == "glm"){
acceptable_region <- which( (max(matrix_acc) - matrix_acc) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA,NA); colnames(acceptable_region) <- c("components","lambda","roughness","acc")
}
for(q in 1:nr){
acceptable_region[q,"roughness"] <- arr_roughStd[acceptable_region[q,"components"], acceptable_region[q,"lambda"], B_id]
acceptable_region[q,"acc"] <- matrix_acc[acceptable_region[q,"components"], acceptable_region[q,"lambda"]]
}
# order by 'acc' and select top 'n_acceptable'
acceptable_region <- acceptable_region[order(acceptable_region[,"acc"], decreasing=T),]
if(nrow(acceptable_region) > n_acceptable){ acceptable_region <- acceptable_region[1:n_acceptable,] # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_acceptable'
}else{                                      n_acceptable <- nrow(acceptable_region) }
if(n_acceptable < n_ensemble){ n_ensemble <- n_acceptable } # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_ensemble'
# re-order by increasing roughness
acceptable_region <- acceptable_region[order(acceptable_region[,"roughness"]),]
# select best models
best_combo_IDs <- acceptable_region[, c("components","lambda")]
best_combo <- cbind(vec_components[best_combo_IDs[,"components"]], vec_lambdas[best_combo_IDs[,"lambda"]]); colnames(best_combo) <- c("Q_opt", "lam_opt")
#---# Levelplot for accuracy and roughness
brewer.div <- colorRampPalette(brewer.pal(11, "Spectral"), interpolate = "spline")
precision <- 3  # decimal places
plotMe_acc <- round(arr_acc[,,B_id], precision); rownames(plotMe_acc) <- vec_components; colnames(plotMe_acc) <- round(vec_lambdas,2)
plotMe_rough <- arr_roughStd[,,B_id]; rownames(plotMe_rough) <- vec_components; colnames(plotMe_rough) <- round(vec_lambdas,2)
# accuracy plot
# pdf(file = paste0(loc_figures, "fig_MAP_accuracy2.pdf"), height=5, width=5, pointsize=12)
colors_at <- seq(floor((10^precision)*min(plotMe_acc))/(10^precision), ceiling((10^precision)*max(plotMe_acc))/(10^precision), len=16)
the_labels <- round(colors_at,3);   the_labels[c(2,3,5,6,8,9,11,12,14,15)] <- ""
levelplot(plotMe_acc, at=colors_at, panel=crossvalidation_levelplot, letter=list(char="a", xloc=1, yloc=ncol(plotMe_acc)), col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="AUC map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
# roughness plot
# pdf(file = paste0(loc_figures, "fig_MAP_roughness2.pdf", height=5, width=5, pointsize=12)
colors_at <- exp(seq(log(min(plotMe_rough)*0.95), log(max(plotMe_rough)*1.05), len=16))
the_labels <- round(colors_at,2);   the_labels[c(2,3,4,5,6,7,8,10,12)] <- ""
levelplot(plotMe_rough, at=colors_at, panel=crossvalidation_levelplot, letter=list(char="b", xloc=1, yloc=ncol(plotMe_acc)), col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="ROUGHNESS map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
if( !(max(matrix_acc) - matrix_acc[best_combo_IDs[1,"components"], best_combo_IDs[1,"lambda"]] <= tau_lam_Q) ){ stop("Closeness criterion not satisfied!") }   # check that the result satisfies the criterion
#---# Test optimal, sub-optimal, and best models
cat("",paste0("Parameter set ",(iii+1),"/",n_modelTypes, " (vr=", L_reduction, ",vs=", ifelse(L_smooth==T,"T","F"), ",vf=", ifelse(L_functional==T,"T","F") ,") | COMPUTING OPTIMAL AND SUBOPTIMAL MODELS:"), sep="\n")
pb_subopt = txtProgressBar(min = 0, max = n_ensemble+2, initial = 0, style = 3)
# best model (with penalisation)
set.seed(17571);  obj_best <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth_w=NULL, intercept=T, lam_cv_type="ocv", lam_vec=best_lambda, reps=N_reps, Q_len=NULL, Q_opt=best_components, Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=F, estimation_w=NULL, bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=F))
setTxtProgressBar(pb_subopt, 1)
# optimal model (without penalisation)
set.seed(17571);  obj_std  <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth_w=NULL, intercept=T, lam_cv_type="n", lam_vec=NULL, reps=N_reps, Q_len=NULL, Q_opt=NULL, Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=F, estimation_w=NULL, bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=F))
setTxtProgressBar(pb_subopt, 2)
# suboptimal models (with penalisation)
suboptimal_MODELS <- list(); suboptimal_RES <- matrix(NA, n_ensemble, 8); colnames(suboptimal_RES) <- c("Q", "R", "lam", "acc", "err_cv", "err_cv_stdev", "err_alt", "err_alt_stdev")
for(jj in 1:n_ensemble){
set.seed(17571);  obj_opt <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth_w=NULL, intercept=T, lam_cv_type="ocv", lam_vec=best_combo[jj,"lam_opt"], reps=N_reps, Q_len=NULL, Q_opt=best_combo[jj,"Q_opt"], Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=F, estimation_w=NULL, bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=F))
suboptimal_RES[jj,"Q"] <- obj_opt$Q_opt
suboptimal_RES[jj,"R"] <- GET_roughness(rowMeans(obj_opt$beta), std=T)
suboptimal_RES[jj,"lam"] <- obj_opt$lam_opt
suboptimal_RES[jj,"acc"] <- mean(obj_opt$AUC_opt[,"test"])
suboptimal_RES[jj,"err_cv"] <- fdaPlot(obj_opt)$err
suboptimal_RES[jj,"err_cv_stdev"] <- fdaPlot(obj_opt)$err_stdev
suboptimal_MODELS[[jj]] <- obj_opt
setTxtProgressBar(pb_subopt, jj+2)
}
# fdaPlot(obj_std, hist_range=c(-20,20))
# fdaPlot(obj_opt)
#{"Q","R","lambda","acc"}
if(L_model == "lm"){
stop("NOT CODED YET! calls 'obj_std$AUC_opt' but that only works for GLM.")
}else if(L_model == "glm"){
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"GLM"),  c("Q","R","lambda","acc","err_cv_smoothest","err_cv_stdev_smoothest")] <- c(obj_std$Q_opt, GET_roughness(rowMeans(obj_std$beta), std=T), obj_std$lam_opt, mean(obj_std$AUC_opt[,"test"]), fdaPlot(obj_std)$err, fdaPlot(obj_std)$err_stdev) # for the non-penalised model, we record the error in the 'smoothest' column, although there's only one model here (lambda=0)
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("Q","R","lambda","acc","err_cv_smoothest","err_cv_stdev_smoothest","err_cv_ensemble","err_cv_stdev_ensemble")] <- c(mean(suboptimal_RES[,"Q"]), mean(suboptimal_RES[,"R"]), mean(suboptimal_RES[,"lam"]), mean(suboptimal_RES[,"acc"]), unname(suboptimal_RES[1,"err_cv"]), unname(suboptimal_RES[1,"err_cv_stdev"]), mean(suboptimal_RES[,"err_cv"]), mean(suboptimal_RES[,"err_cv_stdev"]))
ALL_RES_BEST[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("Q","R","lambda","acc","err_cv_best","err_cv_stdev_best")] <- c(obj_best$Q_opt, GET_roughness(rowMeans(obj_best$beta), std=T), obj_best$lam_opt, mean(obj_best$AUC_opt[,"test"]), fdaPlot(obj_best)$err, fdaPlot(obj_best)$err_stdev)
}
#---# P-values for non-functional variable
# ii_Zpvalues <- (raw_data[,"Species"] %in% SPE) & (raw_data[,"Location"] %in% c(LOC_train,LOC_test)) & (raw_data[,"Generation"] %in% GEN_train)
# balanced_classes <- T
# set.seed(17571);  obj_Zpvalues <- fdaML_train(ll = list(X=X[ii_Zpvalues,], y=factor(y[ii_Zpvalues]), Z=matrix(as.numeric(raw_data[ii_Zpvalues,"Location",drop=F] == "Klesso"), sum(ii_Zpvalues), 1), task=L_task, model=L_model, reduction=L_reduction, smooth_w=NULL, intercept=T, lam_cv_type="n", lam_vec=NULL, reps=N_reps, Q_len=NULL, Q_opt=NULL, Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=balanced_classes, estimation_w=NULL, bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=T))
# plot(obj_Zpvalues$Z_pvalue);  abline(h=0.05, lwd=2);  legend("topright", legend=paste0("median p-value = ", round(median(obj_Zpvalues$Z_pvalue),3)), bty="n", cex=0.9)
#---# Test with alternative dataset
#ii <- (raw_data[,"Feeding_status"] == "Exposed") & (raw_data[,"Infection_status"] %in% c("infectious","uninfectious")) & (raw_data[,"Scanning_day"] %in% c(17,19))
#X_subset_alt <- X[ii,];  y_subset_alt <- rep(0, sum(ii));  y_subset_alt[y[ii] == "infectious"] <- 1;
#
if(DATA_TYPE == "species_A1T1"){
# test with alternative dataset (species_A1T1)
GEN_test <- c("F0", "F1")
ii <- (raw_data[,"Species"] %in% SPE) & (raw_data[,"Location"] %in% LOC_test) & (raw_data[,"Generation"] %in% GEN_train)
X_subset_alt <- X[ii,];  y_subset_alt <- rep(0, sum(ii));  y_subset_alt[raw_data[ii,"Species"] == SPE[1]] <- 1
}else if(DATA_TYPE == "age"){
# test with alternative dataset (age)
ii <- (raw_data[,"Species"] %in% c("gambiae"))
X_subset_alt <- X[ii,];  y_subset_alt <- y[ii]
locTest <- "--"
}else{
stop("'DATA_TYPE' invalid.")
}
cat("",paste0("Parameter set ",(iii+1),"/", n_modelTypes, " (vr=", L_reduction, ",vs=", ifelse(L_smooth==T,"T","F"), ",vf=", ifelse(L_functional==T,"T","F") ,") | TESTING ALTERNATIVE DATASET:"), sep="\n")
pb_alt = txtProgressBar(min = 0, max = n_ensemble+2, initial = 0, style = 3)
# best (with penalisation)
set.seed(17571);  obj_alt_penBEST <- fdaML_predict(obj = obj_best, new_x = X_subset_alt, new_y = y_subset_alt, verbose=F)
setTxtProgressBar(pb_alt, 1)
# optimal (without penalisation)
set.seed(17571);  obj_alt_penNOP <- fdaML_predict(obj = obj_std, new_x = X_subset_alt, new_y = y_subset_alt, verbose=F)
setTxtProgressBar(pb_alt, 2)
# sub-optimal (with penalisation)
alternative_MODELS <- list()
for(jj in 1:n_ensemble){
set.seed(17571);  obj_alt_penYEP <- fdaML_predict(obj = suboptimal_MODELS[[jj]], new_x = X_subset_alt, new_y = y_subset_alt, verbose=F)
# obj_alt_penYEP$errorBreakdown   # confusion matrix
#alternative_MODELS[[jj]] <- alternativeMODELS
suboptimal_RES[jj,"err_alt"] <- obj_alt_penYEP$avgTestErr
suboptimal_RES[jj,"err_alt_stdev"] <- obj_alt_penYEP$stdevTestErr
setTxtProgressBar(pb_alt, jj+2)
}
# re-order by increasing roughness
#suboptimal_RES <- suboptimal_RES[order(suboptimal_RES[,"R"]),]
write.table(x = round(suboptimal_RES, 8), file = paste0(loc_data, DATA_TYPE, "_suboptimalRESULTS_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), "p", toupper(L_model) ,"_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
#fdaPlot(obj_alt_penNOP)
#fdaPlot(obj_alt_penYEP)
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""), "GLM"), c("err_alt_smoothest", "err_alt_stdev_smoothest")] <- c(obj_alt_penNOP$avgTestErr, obj_alt_penNOP$stdevTestErr) # for the non-penalised model, we record the error in the 'smoothest' column, although there's only one model here (lambda=0)
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("err_alt_smoothest", "err_alt_stdev_smoothest", "err_alt_ensemble", "err_alt_stdev_ensemble")] <- c(suboptimal_RES[1,"err_alt"], suboptimal_RES[1,"err_alt_stdev"], mean(suboptimal_RES[,"err_alt"]), mean(suboptimal_RES[jj,"err_alt_stdev"]))
ALL_RES_BEST[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("err_alt_best", "err_alt_stdev_best")] <- c(obj_alt_penBEST$avgTestErr, obj_alt_penBEST$stdevTestErr)
#---# save summary results
iii <- iii + 1
if(DATA_TYPE == "species_A1T1"){
#saveRDS(ALL_RES, file=paste0(loc_data, DATA_TYPE,"_RESULTS__GLM_",toupper(L_reduction), "_", get_fname(SPE,"spe"), "_TrainOn_", LOC_train, get_fname(GEN_train,"gen"),"_TestOn_", LOC_test, get_fname(GEN_test,"gen"), "__iii-", iii, ".Rdata"))
write.table(x = round(ALL_RES,8), file = paste0(loc_data, DATA_TYPE,"_summaryRESULTS_", toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
write.table(x = round(ALL_RES_BEST,8), file = paste0(loc_data, DATA_TYPE,"_summaryRESULTS_BEST_", toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
}else if(DATA_TYPE == "age"){
write.table(x = round(ALL_RES,8), file = paste0(loc_data, DATA_TYPE,"_summaryRESULTS_", toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
}
end_time <- Sys.time()
cat("", paste0("cumulative time = ", round(end_time - start_time, 2), " ", attr(end_time - start_time, "units")), sep="\n")
# loaded_RES <- readRDS(loc_data, "species_A1T1_RESULTS__GLM_PLS_arabVSgamb_TrainOn_LongoF0F1_TestOn_KlessoF0F1.RData")
}#vf
}#vs
}#vr
vr='pls'
for(vs in V_smooth){
for(vf in V_functional){
if(!(L_load %in% c(T,F))){ stop("'L_load' must be either TRUE or FALSE.") }
if(DATA_TYPE == "species_A1T1"){
SPE <- c("arabiensis","gambiae")  # species: {arabiensis , coluzzii , gambiae};  age: {ARAB , GAMB , COLU}
LOC_train <- c("Longo")           # {Longo , Klesso}
LOC_test  <- c("Klesso")          # {Longo , Klesso}
GEN_train <- c("F0","F1")               # {F0 , F1 , F0F1}
#locTrain <- "Longo"
ii <- (raw_data[,"Species"] %in% SPE) & (raw_data[,"Location"] %in% LOC_train) & (raw_data[,"Generation"] %in% GEN_train)
X_subset <- X[ii,];  y_subset <- rep(0, sum(ii));  y_subset[raw_data[ii,"Species"] == SPE[1]] <- 1;
L_task <- "clas"; L_model <- "glm"
}else if(DATA_TYPE == "species_???"){
;
}else if(DATA_TYPE == "age"){
SPE <- "COLU"   # species: {ARABvsGAMB , ARABvsCOLU , COLUvsGAMB}; age: {ARAB , GAMB , COLU}
ii <- (raw_data[,"Species"] == "coluzzii")
X_subset <- X[ii,];  y_subset <- y[ii]
L_task <- "regr"; L_model <- "lm"
}else{
stop("'DATA_TYPE' invalid.")
}
#
L_reduction <- vr
L_smooth <- vs
L_functional <- vf
# smooth here, so use 'smooth=F' in fdaML_train()
if(L_smooth){ X_subset <- fdaSmooth(X_subset) }
N <- ifelse( abs(nrow(X_subset)-length(y_subset)) == 0, nrow(X_subset), stop("'nrow(X)' different from 'length(y)'") );  P <- ncol(X_subset);  palette(rich.colors(length(unique(y_subset))))
# matplot(wvlenghts, t(X_subset), type="l", col=alpha(as.numeric(sum(y_subset==0)!=0)+y_subset,0.4), lty=1, ylim=c(0,2), xlab="wavelength", ylab="signal"); legend("topright", paste("y=",sort(unique(y_subset)),sep=""), horiz=T, lty=1, seg.len=0.8, col=1:length(unique(y_subset)), bty="n", cex=0.8)
########
################   OPTIMISE {# basis K}
########
if(L_functional){
B_opt <- 0.1
#   tau_K <- 0.01
#   vec_basis <- seq(0.1, 1, by=0.1); lb <- length(vec_basis)
#   acc_basis <- rep(NA, lb)
#   cat("",paste0("DETERMINING OPTIMAL FUNCTIONAL REPRESENTATION:"), sep="\n")
#   pb_fda = txtProgressBar(min = 0, max = lb, initial = 0, style = 3);
#   for(nb in 1:lb){
#     set.seed(17571);  obj <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth_w=NULL, intercept=T, lam_cv_type="n", lam_vec=NULL, reps=N_reps, Q_len=NULL, Q_opt=NULL, Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=F, estimation_w=NULL, bspline_dim=floor(vec_basis[nb] * ncol(X)), t_range=wvlenghts, verbose=F))
#     acc_basis[nb] <- mean(obj$perf_cv[,which(obj$Q_vec == obj$Q_opt)])
#     setTxtProgressBar(pb_fda, nb)
#   } # plot(vec_basis, acc_basis, type="l", ylim = c(0.99*min(acc_basis), max(acc_basis))); abline(h = max(acc_basis) - 0.01, col="blue")
#   B_opt <- vec_basis[which((max(acc_basis) - acc_basis) < tau_K)[1]]
}else{
B_opt <- 1
}
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"GLM"),  "K/P"] <- B_opt
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), "K/P"] <- B_opt
########
################   OPTIMISE {# components "Q", penalty parameter "lambda"}
########
#---# Cross-validate (Q,lambda)
vec_basis      <- seq(B_opt, B_opt, by=0.2); lb <- length(vec_basis)
paramsByModel <- list(pls = list(comp_p   = floor(seq(16, 40, len=10)), lam_p   = round(seq(0.5,   10,  len=10), 1),
comp_sp  = floor(seq(16, 30, len=10)), lam_sp  = round(seq(50,    100, len=10), 1),
comp_fp  = floor(seq(16, 30, len=10)), lam_fp  = round(seq(25,    100, len=10), 1),
comp_fsp = floor(seq(10, 30, len=10)), lam_fsp = round(seq(5,     150, len=10), 1)),
pca = list(comp_p   = floor(seq(30, 63, len=10)), lam_p   = round(seq(0.1,   7,   len=10), 1),  # Q=63 is the largest possible b/c of sample sizes
comp_sp  = floor(seq(16, 50, len=10)), lam_sp  = round(seq(0.1,   120, len=10), 1),
comp_fp  = floor(seq(10, 46, len=10)), lam_fp  = round(seq(0.01,  14,  len=10), 1),
comp_fsp = floor(seq(6,  50, len=10)), lam_fsp = round(seq(0.01,  14,  len=10), 1)))
vec_components <- paramsByModel[[L_reduction]][[paste0("comp_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), "p")]];  lc <- length(vec_components)
vec_lambdas    <- paramsByModel[[L_reduction]][[paste0("lam_",  ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), "p")]];  ll <- length(vec_lambdas)
arr_acc <- arr_acc_stdev <- array(NA, c(length(vec_components), length(vec_lambdas), length(vec_basis)), dimnames=list(paste0("c_",vec_components), paste0("l_",vec_lambdas), paste0("b_",vec_basis)))
arr_rough <- arr_roughStd <- arr_acc
if(L_load){ # load data
loadedData <- readRDS(file=paste0(loc_data, DATA_TYPE, "_CV_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"), ".Rdata"))
arr_acc <- loadedData$arr_acc;  arr_acc_stdev <- loadedData$arr_acc_stdev;  arr_rough <- loadedData$arr_rough;  arr_roughStd <- loadedData$arr_roughStd;  vec_basis <- loadedData$vec_basis;  vec_components <- loadedData$vec_components;  vec_lambdas <- loadedData$vec_lambdas
}else{
cat("",paste0("Parameter set ",(iii+1),"/", n_modelTypes, " (vr=", L_reduction, ",vs=", ifelse(L_smooth==T,"T","F"), ",vf=", ifelse(L_functional==T,"T","F") ,") | CROSS-VALIDATING Q/LAMBDA:"), sep="\n")
pb_cv = txtProgressBar(min = 0, max = lb*lc*ll, initial = 0, style = 3);   loopCounter <- 0
for(nb in 1:lb){
for(nc in 1:lc){
for(nl in 1:ll){
set.seed(17571);  obj <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth_w=NULL, intercept=T, lam_cv_type="ocv", lam_vec=vec_lambdas[nl], reps=N_reps, Q_len=NULL, Q_opt=vec_components[nc], Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=F, estimation_w=NULL, bspline_dim=floor(vec_basis[nb] * ncol(X)), t_range=wvlenghts, verbose=T))
arr_acc[nc,nl,nb] <- mean(obj$perf_cv[,which(obj$Q_vec == obj$Q_opt)])
arr_acc_stdev[nc,nl,nb] <- sd(obj$perf_cv[,which(obj$Q_vec == obj$Q_opt)])
arr_rough[nc,nl,nb] <- mean(obj$beta_roughness)
arr_roughStd[nc,nl,nb] <- mean(obj$beta_roughnessStd)
loopCounter <- loopCounter + 1;   setTxtProgressBar(pb_cv, loopCounter)
}
}
}
cv_list <- list(arr_acc = arr_acc,
arr_acc_stdev = arr_acc_stdev,
arr_rough = arr_rough,
arr_roughStd = arr_roughStd,
vec_basis = vec_basis,
vec_components = vec_components,
vec_lambdas = vec_lambdas)
saveRDS(cv_list, file=paste0(loc_data, DATA_TYPE,"_CV_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"), ".Rdata"))
}
#---# Diagnostic plots
# set.seed(17571);  obj_dgnostics <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth_w=NULL, intercept=T, lam_cv_type="n", lam_vec=NULL, reps=N_reps, Q_len=NULL, Q_opt=NULL, Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=F, estimation_w=NULL, bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=T))
# fdaPlot(obj_dgnostics)
#---# Determine best model (highest accuracy) - to be used in "obj_best" below
B_id <- 1 # this is the first (and only) element of 'arr_acc' and similar arrays, because 'vec_basis' only has the optimal pre-computed ratio K/P = B_opt
best_idx <- which(arr_acc[,,B_id] == max(arr_acc), arr.ind = TRUE)
best_components <- vec_components[best_idx[,'row']]
best_lambda <- vec_lambdas[best_idx[,'row']]
#---# Determine parameter region for ensemble meodel
matrix_acc <- arr_acc[,,B_id]
tau_lam_Q <- 0.01
n_acceptable <- 25  # maximum number of models in the acceptable region
n_ensemble   <- 5   # maximum number of models in the ensemble (most SMOOTH from the models in the acceptable region)
if(n_ensemble > n_acceptable){ stop("'n_acceptable' must be larger or equal to 'n_ensemble'.") }
# compute acceptable region
if(L_model == "lm"){
stop("REVISE OPTIMAL REGION FORMULA + MULTIPLE MODELS NOT CODED YET.")
acceptable_region <- which( (matrix_acc - min(matrix_acc)) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA); colnames(acceptable_region) <- c("components","lambda","roughness")
}else if (L_model == "glm"){
acceptable_region <- which( (max(matrix_acc) - matrix_acc) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA,NA); colnames(acceptable_region) <- c("components","lambda","roughness","acc")
}
for(q in 1:nr){
acceptable_region[q,"roughness"] <- arr_roughStd[acceptable_region[q,"components"], acceptable_region[q,"lambda"], B_id]
acceptable_region[q,"acc"] <- matrix_acc[acceptable_region[q,"components"], acceptable_region[q,"lambda"]]
}
# order by 'acc' and select top 'n_acceptable'
acceptable_region <- acceptable_region[order(acceptable_region[,"acc"], decreasing=T),]
if(nrow(acceptable_region) > n_acceptable){ acceptable_region <- acceptable_region[1:n_acceptable,] # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_acceptable'
}else{                                      n_acceptable <- nrow(acceptable_region) }
if(n_acceptable < n_ensemble){ n_ensemble <- n_acceptable } # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_ensemble'
# re-order by increasing roughness
acceptable_region <- acceptable_region[order(acceptable_region[,"roughness"]),]
# select best models
best_combo_IDs <- acceptable_region[, c("components","lambda")]
best_combo <- cbind(vec_components[best_combo_IDs[,"components"]], vec_lambdas[best_combo_IDs[,"lambda"]]); colnames(best_combo) <- c("Q_opt", "lam_opt")
#---# Levelplot for accuracy and roughness
brewer.div <- colorRampPalette(brewer.pal(11, "Spectral"), interpolate = "spline")
precision <- 3  # decimal places
plotMe_acc <- round(arr_acc[,,B_id], precision); rownames(plotMe_acc) <- vec_components; colnames(plotMe_acc) <- round(vec_lambdas,2)
plotMe_rough <- arr_roughStd[,,B_id]; rownames(plotMe_rough) <- vec_components; colnames(plotMe_rough) <- round(vec_lambdas,2)
# accuracy plot
# pdf(file = paste0(loc_figures, "fig_MAP_accuracy2.pdf"), height=5, width=5, pointsize=12)
colors_at <- seq(floor((10^precision)*min(plotMe_acc))/(10^precision), ceiling((10^precision)*max(plotMe_acc))/(10^precision), len=16)
the_labels <- round(colors_at,3);   the_labels[c(2,3,5,6,8,9,11,12,14,15)] <- ""
levelplot(plotMe_acc, at=colors_at, panel=crossvalidation_levelplot, letter=list(char="a", xloc=1, yloc=ncol(plotMe_acc)), col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="AUC map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
# roughness plot
# pdf(file = paste0(loc_figures, "fig_MAP_roughness2.pdf", height=5, width=5, pointsize=12)
colors_at <- exp(seq(log(min(plotMe_rough)*0.95), log(max(plotMe_rough)*1.05), len=16))
the_labels <- round(colors_at,2);   the_labels[c(2,3,4,5,6,7,8,10,12)] <- ""
levelplot(plotMe_rough, at=colors_at, panel=crossvalidation_levelplot, letter=list(char="b", xloc=1, yloc=ncol(plotMe_acc)), col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="ROUGHNESS map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
if( !(max(matrix_acc) - matrix_acc[best_combo_IDs[1,"components"], best_combo_IDs[1,"lambda"]] <= tau_lam_Q) ){ stop("Closeness criterion not satisfied!") }   # check that the result satisfies the criterion
#---# Test optimal, sub-optimal, and best models
cat("",paste0("Parameter set ",(iii+1),"/",n_modelTypes, " (vr=", L_reduction, ",vs=", ifelse(L_smooth==T,"T","F"), ",vf=", ifelse(L_functional==T,"T","F") ,") | COMPUTING OPTIMAL AND SUBOPTIMAL MODELS:"), sep="\n")
pb_subopt = txtProgressBar(min = 0, max = n_ensemble+2, initial = 0, style = 3)
# best model (with penalisation)
set.seed(17571);  obj_best <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth_w=NULL, intercept=T, lam_cv_type="ocv", lam_vec=best_lambda, reps=N_reps, Q_len=NULL, Q_opt=best_components, Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=F, estimation_w=NULL, bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=F))
setTxtProgressBar(pb_subopt, 1)
# optimal model (without penalisation)
set.seed(17571);  obj_std  <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth_w=NULL, intercept=T, lam_cv_type="n", lam_vec=NULL, reps=N_reps, Q_len=NULL, Q_opt=NULL, Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=F, estimation_w=NULL, bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=F))
setTxtProgressBar(pb_subopt, 2)
# suboptimal models (with penalisation)
suboptimal_MODELS <- list(); suboptimal_RES <- matrix(NA, n_ensemble, 8); colnames(suboptimal_RES) <- c("Q", "R", "lam", "acc", "err_cv", "err_cv_stdev", "err_alt", "err_alt_stdev")
for(jj in 1:n_ensemble){
set.seed(17571);  obj_opt <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth_w=NULL, intercept=T, lam_cv_type="ocv", lam_vec=best_combo[jj,"lam_opt"], reps=N_reps, Q_len=NULL, Q_opt=best_combo[jj,"Q_opt"], Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=F, estimation_w=NULL, bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=F))
suboptimal_RES[jj,"Q"] <- obj_opt$Q_opt
suboptimal_RES[jj,"R"] <- GET_roughness(rowMeans(obj_opt$beta), std=T)
suboptimal_RES[jj,"lam"] <- obj_opt$lam_opt
suboptimal_RES[jj,"acc"] <- mean(obj_opt$AUC_opt[,"test"])
suboptimal_RES[jj,"err_cv"] <- fdaPlot(obj_opt)$err
suboptimal_RES[jj,"err_cv_stdev"] <- fdaPlot(obj_opt)$err_stdev
suboptimal_MODELS[[jj]] <- obj_opt
setTxtProgressBar(pb_subopt, jj+2)
}
# fdaPlot(obj_std, hist_range=c(-20,20))
# fdaPlot(obj_opt)
#{"Q","R","lambda","acc"}
if(L_model == "lm"){
stop("NOT CODED YET! calls 'obj_std$AUC_opt' but that only works for GLM.")
}else if(L_model == "glm"){
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"GLM"),  c("Q","R","lambda","acc","err_cv_smoothest","err_cv_stdev_smoothest")] <- c(obj_std$Q_opt, GET_roughness(rowMeans(obj_std$beta), std=T), obj_std$lam_opt, mean(obj_std$AUC_opt[,"test"]), fdaPlot(obj_std)$err, fdaPlot(obj_std)$err_stdev) # for the non-penalised model, we record the error in the 'smoothest' column, although there's only one model here (lambda=0)
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("Q","R","lambda","acc","err_cv_smoothest","err_cv_stdev_smoothest","err_cv_ensemble","err_cv_stdev_ensemble")] <- c(mean(suboptimal_RES[,"Q"]), mean(suboptimal_RES[,"R"]), mean(suboptimal_RES[,"lam"]), mean(suboptimal_RES[,"acc"]), unname(suboptimal_RES[1,"err_cv"]), unname(suboptimal_RES[1,"err_cv_stdev"]), mean(suboptimal_RES[,"err_cv"]), mean(suboptimal_RES[,"err_cv_stdev"]))
ALL_RES_BEST[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("Q","R","lambda","acc","err_cv_best","err_cv_stdev_best")] <- c(obj_best$Q_opt, GET_roughness(rowMeans(obj_best$beta), std=T), obj_best$lam_opt, mean(obj_best$AUC_opt[,"test"]), fdaPlot(obj_best)$err, fdaPlot(obj_best)$err_stdev)
}
#---# P-values for non-functional variable
# ii_Zpvalues <- (raw_data[,"Species"] %in% SPE) & (raw_data[,"Location"] %in% c(LOC_train,LOC_test)) & (raw_data[,"Generation"] %in% GEN_train)
# balanced_classes <- T
# set.seed(17571);  obj_Zpvalues <- fdaML_train(ll = list(X=X[ii_Zpvalues,], y=factor(y[ii_Zpvalues]), Z=matrix(as.numeric(raw_data[ii_Zpvalues,"Location",drop=F] == "Klesso"), sum(ii_Zpvalues), 1), task=L_task, model=L_model, reduction=L_reduction, smooth_w=NULL, intercept=T, lam_cv_type="n", lam_vec=NULL, reps=N_reps, Q_len=NULL, Q_opt=NULL, Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=balanced_classes, estimation_w=NULL, bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=T))
# plot(obj_Zpvalues$Z_pvalue);  abline(h=0.05, lwd=2);  legend("topright", legend=paste0("median p-value = ", round(median(obj_Zpvalues$Z_pvalue),3)), bty="n", cex=0.9)
#---# Test with alternative dataset
#ii <- (raw_data[,"Feeding_status"] == "Exposed") & (raw_data[,"Infection_status"] %in% c("infectious","uninfectious")) & (raw_data[,"Scanning_day"] %in% c(17,19))
#X_subset_alt <- X[ii,];  y_subset_alt <- rep(0, sum(ii));  y_subset_alt[y[ii] == "infectious"] <- 1;
#
if(DATA_TYPE == "species_A1T1"){
# test with alternative dataset (species_A1T1)
GEN_test <- c("F0", "F1")
ii <- (raw_data[,"Species"] %in% SPE) & (raw_data[,"Location"] %in% LOC_test) & (raw_data[,"Generation"] %in% GEN_train)
X_subset_alt <- X[ii,];  y_subset_alt <- rep(0, sum(ii));  y_subset_alt[raw_data[ii,"Species"] == SPE[1]] <- 1
}else if(DATA_TYPE == "age"){
# test with alternative dataset (age)
ii <- (raw_data[,"Species"] %in% c("gambiae"))
X_subset_alt <- X[ii,];  y_subset_alt <- y[ii]
locTest <- "--"
}else{
stop("'DATA_TYPE' invalid.")
}
cat("",paste0("Parameter set ",(iii+1),"/", n_modelTypes, " (vr=", L_reduction, ",vs=", ifelse(L_smooth==T,"T","F"), ",vf=", ifelse(L_functional==T,"T","F") ,") | TESTING ALTERNATIVE DATASET:"), sep="\n")
pb_alt = txtProgressBar(min = 0, max = n_ensemble+2, initial = 0, style = 3)
# best (with penalisation)
set.seed(17571);  obj_alt_penBEST <- fdaML_predict(obj = obj_best, new_x = X_subset_alt, new_y = y_subset_alt, verbose=F)
setTxtProgressBar(pb_alt, 1)
# optimal (without penalisation)
set.seed(17571);  obj_alt_penNOP <- fdaML_predict(obj = obj_std, new_x = X_subset_alt, new_y = y_subset_alt, verbose=F)
setTxtProgressBar(pb_alt, 2)
# sub-optimal (with penalisation)
alternative_MODELS <- list()
for(jj in 1:n_ensemble){
set.seed(17571);  obj_alt_penYEP <- fdaML_predict(obj = suboptimal_MODELS[[jj]], new_x = X_subset_alt, new_y = y_subset_alt, verbose=F)
# obj_alt_penYEP$errorBreakdown   # confusion matrix
#alternative_MODELS[[jj]] <- alternativeMODELS
suboptimal_RES[jj,"err_alt"] <- obj_alt_penYEP$avgTestErr
suboptimal_RES[jj,"err_alt_stdev"] <- obj_alt_penYEP$stdevTestErr
setTxtProgressBar(pb_alt, jj+2)
}
# re-order by increasing roughness
#suboptimal_RES <- suboptimal_RES[order(suboptimal_RES[,"R"]),]
write.table(x = round(suboptimal_RES, 8), file = paste0(loc_data, DATA_TYPE, "_suboptimalRESULTS_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), "p", toupper(L_model) ,"_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
#fdaPlot(obj_alt_penNOP)
#fdaPlot(obj_alt_penYEP)
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""), "GLM"), c("err_alt_smoothest", "err_alt_stdev_smoothest")] <- c(obj_alt_penNOP$avgTestErr, obj_alt_penNOP$stdevTestErr) # for the non-penalised model, we record the error in the 'smoothest' column, although there's only one model here (lambda=0)
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("err_alt_smoothest", "err_alt_stdev_smoothest", "err_alt_ensemble", "err_alt_stdev_ensemble")] <- c(suboptimal_RES[1,"err_alt"], suboptimal_RES[1,"err_alt_stdev"], mean(suboptimal_RES[,"err_alt"]), mean(suboptimal_RES[jj,"err_alt_stdev"]))
ALL_RES_BEST[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("err_alt_best", "err_alt_stdev_best")] <- c(obj_alt_penBEST$avgTestErr, obj_alt_penBEST$stdevTestErr)
#---# save summary results
iii <- iii + 1
if(DATA_TYPE == "species_A1T1"){
#saveRDS(ALL_RES, file=paste0(loc_data, DATA_TYPE,"_RESULTS__GLM_",toupper(L_reduction), "_", get_fname(SPE,"spe"), "_TrainOn_", LOC_train, get_fname(GEN_train,"gen"),"_TestOn_", LOC_test, get_fname(GEN_test,"gen"), "__iii-", iii, ".Rdata"))
write.table(x = round(ALL_RES,8), file = paste0(loc_data, DATA_TYPE,"_summaryRESULTS_", toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
write.table(x = round(ALL_RES_BEST,8), file = paste0(loc_data, DATA_TYPE,"_summaryRESULTS_BEST_", toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
}else if(DATA_TYPE == "age"){
write.table(x = round(ALL_RES,8), file = paste0(loc_data, DATA_TYPE,"_summaryRESULTS_", toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
}
end_time <- Sys.time()
cat("", paste0("cumulative time = ", round(end_time - start_time, 2), " ", attr(end_time - start_time, "units")), sep="\n")
# loaded_RES <- readRDS(loc_data, "species_A1T1_RESULTS__GLM_PLS_arabVSgamb_TrainOn_LongoF0F1_TestOn_KlessoF0F1.RData")
}#vf
}#vs
# pdf(file = paste0(loc_figures,"fig_spectra_color3.pdf"), height=5, width=10, pointsize=12)
{
X_plot <- X[y %in% c("arabiensis","gambiae"),]
y_plot <- factor(y[y %in% c("arabiensis","gambiae")])
set.seed(52);  ii <- sample(nrow(X_plot), size=30)
col_arab <- rgb(0,1,0,0.7);  col_gamb <- rgb(0,0,1,0.7)
col_vec <- as.character(y_plot[ii]); col_vec[col_vec=="arabiensis"] <- col_arab; col_vec[col_vec=="gambiae"] <- col_gamb  # skyblue rgb(1,0,0,0.6)
offset <- 1;   cols <- as.numeric(y_plot[ii]) + offset
matplot(wvlenghts, t(X_plot[ii,]), type="l", col=col_vec, lty=1, lwd=2, xlim=c(350,2500), ylim=c(0.2,1.5), xaxt="n", bty="n", xlab="wavelength (nm)", ylab="absorbance")
legend_labels <- c("An. arabiensis","An. gambiae s.s.")
legend("top", legend=legend_labels, lty=1, lwd=2, seg.len=1.3, col=c(col_arab,col_gamb), title=expression(bold("Species")), horiz=T, bty="n")
axis(1,at=seq(300,2500,len=12))
}
pdf(file = paste0(loc_figures,"fig_spectra_color3.pdf"), height=5, width=10, pointsize=12)
# pdf(file = paste0(loc_figures,"fig_spectra_color3.pdf"), height=5, width=10, pointsize=12)
{
X_plot <- X[y %in% c("arabiensis","gambiae"),]
y_plot <- factor(y[y %in% c("arabiensis","gambiae")])
set.seed(52);  ii <- sample(nrow(X_plot), size=30)
col_arab <- rgb(0,1,0,0.7);  col_gamb <- rgb(0,0,1,0.7)
col_vec <- as.character(y_plot[ii]); col_vec[col_vec=="arabiensis"] <- col_arab; col_vec[col_vec=="gambiae"] <- col_gamb  # skyblue rgb(1,0,0,0.6)
offset <- 1;   cols <- as.numeric(y_plot[ii]) + offset
matplot(wvlenghts, t(X_plot[ii,]), type="l", col=col_vec, lty=1, lwd=2, xlim=c(350,2500), ylim=c(0.2,1.5), xaxt="n", bty="n", xlab="wavelength (nm)", ylab="absorbance")
legend_labels <- c("An. arabiensis","An. gambiae s.s.")
legend("top", legend=legend_labels, lty=1, lwd=2, seg.len=1.3, col=c(col_arab,col_gamb), title=expression(bold("Species")), horiz=T, bty="n")
axis(1,at=seq(300,2500,len=12))
}
dev.off()
dim(X)
data_B_A1T1$n_replics
sum(data_B_A1T1$n_replics)
sum(data_B_A1T1$n_replics)/length(data_B_A1T1$n_replics)
hist(v)
hist(data_B_A1T1$n_replics)
table(data_B_A1T1$n_replics)
table(data_B_A1T1$n_replics)/sum(data_B_A1T1$n_replics)
table(data_B_A1T1$n_replics)/length(data_B_A1T1$n_replics)
sum(table(data_B_A1T1$n_replics)/length(data_B_A1T1$n_replics))
