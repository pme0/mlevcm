B_A2T2 = 1:4,                # Burkina Faso experiments, activity 2 test 2 updated (infection)
B_A2E2 = 1:4,                # Burkina Faso experiments, activity 2 experient 2 (infection)
B_A4E4 = 1:4)                # Burkina Faso experiments, activity 4 experient 4 (infection, timepoint 1)
}else{
Params$tp <- list(A1 = 1,
A2 = 1,
A3 = 1,
A4 = 1,
B_A2T2 = 1,
B_A2E2 = 1,
B_A1T1 = 1,
B_A1E1 = 1,
B_A4E4 = 1)
}
load_A1 <- function(Params){
# read data
data_A1 <-  read.table(file = "~/Dropbox/research/projects/nirs/data/datasets/experiments_2017_SouthKensington/A1_sporozoites/A1_sporozoites_01-06-2017_y.txt", header=T, na.strings = "NA")
target_pos <- Params$tp$A1  # {1,2,3}
select <- (!is.na(data_A1[,"Position"])) & (!is.na(data_A1[,"Sporozoites"])) & (data_A1[,"Position"] %in% target_pos)
#select[153:154] <- FALSE # outliers, etc.
# indices of repetitions for each mosquito
idx_A1 <- list()
for(i in unique(data_A1[select,"Mosquito_ID"])){
rng <- which(data_A1[,"Mosquito_ID"] == i)   #which((data_A1[,"Mosquito_ID"])[data_A1[,"Mosquito_ID"] == i])
aux <- (data_A1[rng,"Position"] %in% target_pos) & !is.na(data_A1[rng,"Position"]) & !is.na(data_A1[rng,"Sporozoites"])
idx_A1[[i]] <- rng[aux]
}
n_replics <- unlist(lapply(idx_A1, length))  # store how many repeated observations for each specimen
# read predictor (X)
nx <- 212  # number of spectra files
dx <- matrix(0, nx, 2151)
f_base <- "~/Dropbox/research/projects/nirs/data/datasets/experiments_2017_SouthKensington/A1_sporozoites/AnS_sporo_"
for(k in 1:nx){
f_name <- paste(f_base, formatC(k, width = 5,flag = 0),".txt", sep="")
fk <- read.table(file = f_name)
dx[k,] <- fk$V1
}
# average replications
if(Params$avg_replics){
data_X <- c()
for(i in unique(data_A1[select,"Mosquito_ID"])){
if(length(idx_A1[[i]]) > 1){
data_X <- rbind(data_X, colMeans(dx[idx_A1[[i]],]))
}else{
data_X <- rbind(data_X, dx[idx_A1[[i]],])
}
}
}else{
data_X <- dx[select,]
}
# read response (y)
i_y <- select & ((1:nrow(data_A1)) %in% unlist(sapply(idx_A1, "[[", 1)))
data_y <- data_A1[i_y,"Sporozoites"]
return(list(X = data_X, y = data_y, n_replics = n_replics[n_replics != 0], raw_data = data_A1[i_y,]))
# re-save with simple layout
#data_export <- data.frame(y = y, X = X)
#write.table(data_export, file="~/Dropbox/research/projects/nirs/data/datasets/experiments_Tom/A1_sporozoites/DATASET_sporozoites_2017_06_01.txt", sep=",", row.names=F, col.names=T)
}#load_A1
load_A2 <- function(Params){
# read response (y)
data_A2 <-  read.table(file = "~/Dropbox/research/projects/nirs/data/datasets/experiments_2017_SouthKensington/A2_oocysts/Notes_oocysts_2017_06_05_y.txt", header=T, na.strings = "NA")
target_pos <- Params$tp$A2  # {1,2,3,4}
select <- (!is.na(data_A2[,"Mosquito_ID"])) & (!is.na(data_A2[,"Position"])) & (!is.na(data_A2[,"Oocysts"])) & (data_A2[,"Position"] %in% target_pos)
#select <- data_A2[,2] == target_pos & !is.na(data_A2[,1]) & !is.na(data_A2[,2]) & !is.na(data_A2[,3]) & !is.na(data_A2[,4])
if(!is.na(which(data_A2[,"Mosquito_ID"]==39 & (data_A2[,"Position"] %in% target_pos))[2])) select[which(data_A2[,"Mosquito_ID"]==39 & (data_A2[,"Position"] %in% target_pos))[2]] <- F  # repeated position, see xlsx notes
data_y <- data_A2[select,4]
# indices of repetitions for each mosquito
idx_A2 <- list()
for(i in unique(data_A2[select,"Mosquito_ID"])){
rng <- which(data_A2[,"Mosquito_ID"] == i)
aux <- (data_A2[rng,"Position"] %in% target_pos) & !is.na(data_A2[rng,"Position"]) & !is.na(data_A2[rng,"Oocysts"])
idx_A2[[i]] <- rng[aux]
}
n_replics <- unlist(lapply(idx_A2, length))  # store how many repeated observations for each specimen
# read predictor (X)
nx <- 335  # number of spectra files
dx <- matrix(0, nx, 2151)
f_base <- "~/Dropbox/research/projects/nirs/data/datasets/experiments_2017_SouthKensington/A2_oocysts/AnS_oocysts_"
for(k in 1:nx){
f_name <- paste(f_base, formatC(k, width = 5,flag = 0),".txt", sep="")
fk <- read.table(file = f_name)
dx[k,] <- fk$V1
}
data_X <- dx[select,]
# average replications
# if(Params$avg_replics){
#   data_X <- c()
#   for(i in unique(data_A2[select,"Mosquito_ID"])){
#     if(length(idx_A2[[i]]) > 1){
#       data_X <- rbind(data_X, colMeans(dx[idx_A2[[i]],]))
#     }else{
#       data_X <- rbind(data_X, dx[idx_A2[[i]],])
#     }
#   }
# }else{
#   data_X <- dx[select,]
# }
# read response (y)
i_y <- select & ((1:nrow(data_A2)) %in% unlist(sapply(idx_A2, "[[", 1)))
data_y <- data_A2[i_y,"Oocysts"]
return(list(X = data_X, y = data_y, n_replics = n_replics[n_replics != 0], raw_data = data_A2[i_y,]))
}#load_A2
load_A3 <- function(Params){
# read data
data_A3 <-  read.table(file = "~/Dropbox/research/projects/nirs/data/datasets/experiments_2017_SouthKensington/A3_sporozoites/A3_sporozoites_29-06-2017_y.txt", header=T, na.strings = "NA")
target_pos <- Params$tp$A3 #{1,2}
select <- (!is.na(data_A3[,"Position"])) & (!is.na(data_A3[,"Sporozoites"])) & (data_A3[,"Position"] %in% target_pos)
select[139:150] <- FALSE # data recording error
select[153:154] <- FALSE # spectra 154 is an outlier [eliminate all replications to make averaging replicates easier]
# indices of repetitions for each mosquito
idx_A3 <- list()
for(i in unique(data_A3[select,"Mosquito_ID"])){
rng <- which(data_A3[,"Mosquito_ID"] == i)
aux <- (data_A3[rng,"Position"] %in% target_pos) & !is.na(data_A3[rng,"Position"]) & !is.na(data_A3[rng,"Sporozoites"])
idx_A3[[i]] <- rng[aux]
}
n_replics <- unlist(lapply(idx_A3, length))  # store how many repeated observations for each specimen
# read predictor (X)
nx <- 180  # number of spectra files
dx <- matrix(0, nx, 2151)
f_base <- "~/Dropbox/research/projects/nirs/data/datasets/experiments_2017_SouthKensington/A3_sporozoites/sporozoites_29June2017_"
for(k in 1:nx){
f_name <- paste(f_base, formatC(k, width = 5,flag = 0),".txt", sep="")
fk <- read.table(file = f_name)
dx[k,] <- fk$V1
}
# average replications
if(Params$avg_replics){
data_X <- c()
for(i in unique(data_A3[select,"Mosquito_ID"])){
if(length(idx_A3[[i]]) > 1){
data_X <- rbind(data_X, colMeans(dx[idx_A3[[i]],]))
}else{
data_X <- rbind(data_X, dx[idx_A3[[i]],])
}
}
}else{
data_X <- dx[select,]
}
# read response (y)
i_y <- select & ((1:nrow(data_A3)) %in% unlist(sapply(idx_A3, "[[", 1)))
data_y <- data_A3[i_y,"Sporozoites"]
return(list(X = data_X, y = data_y, n_replics = n_replics[n_replics != 0], raw_data = data_A3[i_y,]))
}#load_A3
load_A4 <- function(Params){
# read data
data_A4 <-  read.table(file = "~/Dropbox/research/projects/nirs/data/datasets/experiments_2017_SouthKensington/A4_sporozoites/A4_sporozoites_19-07-2017_y.txt", header=T, na.strings = "NA")
data_A4 <- cbind(1:nrow(data_A4), data_A4); colnames(data_A4)[1] <- "Scan_ID"
target_pos <- Params$tp$A4 #{1,2,3,4}
select <- (!is.na(data_A4[,"Position"])) & (!is.na(data_A4[,"Sporozoites"])) & (data_A4[,"Position"] %in% target_pos) #& (!(1:nrow(data_A4) %in% 139:150))
#select[153:154] <- FALSE # outliers, recording errors, etc.
# indices of repetitions for each mosquito
idx_A4 <- list()
for(i in unique(data_A4[select,"Mosquito_ID"])){
rng <- which(data_A4[,"Mosquito_ID"] == i)
aux <- (data_A4[rng,"Position"] %in% target_pos) & !is.na(data_A4[rng,"Position"]) & !is.na(data_A4[rng,"Sporozoites"])
idx_A4[[i]] <- rng[aux]
}
n_replics <- unlist(lapply(idx_A4, length))  # store how many repeated observations for each specimen
# read spectra (X)
nx <- 328  # number of spectra files
dx <- matrix(0, nx, 2151)
f_base <- "~/Dropbox/research/projects/nirs/data/datasets/experiments_2017_SouthKensington/A4_sporozoites/sporozoites_19July2017_"
for(k in 1:nx){
f_name <- paste(f_base, formatC(k, width = 5,flag = 0),".txt", sep="")
fk <- read.table(file = f_name)
dx[k,] <- fk$V1
}
# average replications
if(Params$avg_replics){
data_X <- c()
for(i in unique(data_A4[select,"Mosquito_ID"])){
if(length(idx_A4[[i]]) > 1){
data_X <- rbind(data_X, colMeans(dx[idx_A4[[i]],]))
}else{
data_X <- rbind(data_X, dx[idx_A4[[i]],])
}
}
}else{
data_X <- dx[select,]
}
# read response (y)
i_y <- select & ((1:nrow(data_A4)) %in% unlist(sapply(idx_A4, "[[", 1)))
data_y <- data_A4[i_y,"Sporozoites"]
return(list(X = data_X, y = data_y, n_replics = n_replics[n_replics != 0], raw_data = data_A4[i_y,]))
}#load_A4
load_B_A1T1 <- function(Params){
# read data
#data <-  read.csv(file = "~/Dropbox/research/projects/nirs/data/datasets/Burkina NIRS Data/Activity 1 - Age/NIRS_E1T1_(PEDRO).csv", header=T, na.strings = "NA")
data <-  read.csv(file = "~/DROPBOX_overflow/research/projects/nirs/data/datasets/Burkina NIRS Data/Activity 1 - Age/NIRS_E1T1_(PEDRO).csv", header=T, na.strings = "NA")
target_pos <- Params$tp$B_A1T1  # {1,2,3,4}
select <- (!is.na(data[,"Position"])) & (!is.na(data[,"Age"])) & (!is.na(data[,"Location"])) & (!is.na(data[,"Generation"])) & (!is.na(data[,"Species"])) & (data[,"Position"] %in% target_pos)
#select[153:154] <- FALSE # outliers, etc.
unique_IDs <- unique(data[select,"Mosquito_ID"])
# indices of repetitions for each mosquito
idx <- list()
for(i in unique_IDs){
rng <- which(data[,"Mosquito_ID"] == i)   #which((data[,"Mosquito_ID"])[data[,"Mosquito_ID"] == i])
aux <- (data[rng,"Position"] %in% target_pos) & !is.na(data[rng,"Position"]) & !is.na(data[rng,"Age"]) & (!is.na(data[rng,"Location"])) & (!is.na(data[rng,"Generation"])) & (!is.na(data[rng,"Species"]))
idx[[i]] <- rng[aux]
}
n_replics <- unlist(lapply(idx, length))  # store how many repeated observations for each specimen
# read predictor (X)
dates    <- c("8Oct17","9Oct17","10Oct17")
nx_dates <- c(  695   ,  782   ,   1025  )
nx <- sum(nx_dates)  # number of spectra files
dx <- matrix(0, nx, 2151);  kk <- 0
for(day in dates){
for(k in 0:(nx_dates[which(dates == day)]-1)){
kk <- kk + 1
#f_name <- paste0("~/Dropbox/research/projects/nirs/data/datasets/Burkina NIRS Data/Activity 1 - Age/Test 1B/E1Test1_",day,"_", formatC(k, width = 5,flag = 0),".txt")
f_name <- paste0("~/DROPBOX_overflow/research/projects/nirs/data/datasets/Burkina NIRS Data/Activity 1 - Age/Test 1B/E1Test1_",day,"_", formatC(k, width = 5,flag = 0),".txt")
dx[kk,] <- read.table(file = f_name, header=T, sep="\t")[,2]
}
}
# average replications
if(Params$avg_replics){
data_X <- c()
for(i in unique_IDs){
if(length(idx[[i]]) > 1){
data_X <- rbind(data_X, colMeans(dx[idx[[i]],]))
}else{
data_X <- rbind(data_X, dx[idx[[i]],])
}
}
}else{
data_X <- dx[select,]
}
# read response (y)
i_y <- select & ((1:nrow(data)) %in% unlist(sapply(idx, "[[", 1)))
data_y <- factor(data[i_y,"Species"])
# raw data
raw_data <- data[i_y,]   #  table(raw_data[,c("Species","Location","Generation")])
return(list(X = data_X, y = data_y, n_replics = n_replics[n_replics != 0], raw_data = raw_data))
# re-save with simple layout
#data_export <- data.frame(y = y, X = X)
#write.table(data_export, file="~/Dropbox/research/projects/nirs/data/datasets/experiments_Tom/A1_sporozoites/DATASET_sporozoites_2017_06_01.txt", sep=",", row.names=F, col.names=T)
}#load_B_A1T1
#================================   B_A1T1  BURKINA FASO, ACTIVITY 1 EXPERIMENT 1 (AGE, test)
data_B_A1T1 <- load_B_A1T1(Params);   X <- data_B_A1T1$X;   y <- data_B_A1T1$y;   raw_data <- data_B_A1T1$raw_data
########   SET PATHS
loc_data     <- "~/Dropbox/research/projects/nirs/typesetting/nirs_paper2_fda/data/"
loc_figures  <- "~/Dropbox/research/projects/nirs/typesetting/nirs_paper2_fda/figures/"
########   LOAD DATA
# load data 'B_A1T1' OR 'B_A2E2' from "cleanRealData.R"
########   AUXILIARY FUNCTIONS
get_fname <- function(x, xtype){
if(xtype == "spe"){
return( paste0(paste(strsplit(x[1], split="")[[1]][1:4], collapse=""), "VS", paste(strsplit(x[2], split="")[[1]][1:4], collapse="")) )
}else if (xtype == "gen"){
return(paste0(x, collapse=""))
}
}
########   PLOT SPECTRA
palette(rich.colors(5))
wvlenghts <- 350:2500
# pdf(file = paste0(loc_figures,"fig_spectra_color3.pdf"), height=5, width=10, pointsize=12)
{
X_plot <- X[y %in% c("arabiensis","gambiae"),]
y_plot <- factor(y[y %in% c("arabiensis","gambiae")])
set.seed(52);  ii <- sample(nrow(X_plot), size=30)
col_arab <- rgb(0,1,0,0.7);  col_gamb <- rgb(0,0,1,0.7)
col_vec <- as.character(y_plot[ii]); col_vec[col_vec=="arabiensis"] <- col_arab; col_vec[col_vec=="gambiae"] <- col_gamb  # skyblue rgb(1,0,0,0.6)
offset <- 1;   cols <- as.numeric(y_plot[ii]) + offset
matplot(wvlenghts, t(X_plot[ii,]), type="l", col=col_vec, lty=1, lwd=2, xlim=c(350,2500), ylim=c(0.2,1.5), xaxt="n", bty="n", xlab="wavelength (nm)", ylab="absorbance")
legend_labels <- c("An. arabiensis","An. gambiae")
legend("top", legend=legend_labels, lty=1, lwd=2, seg.len=1.3, col=c(col_arab,col_gamb), title=expression(bold("Species")), horiz=T, bty="n")
axis(1,at=seq(300,2500,len=12))
}
# dev.off()
##########################################################################################################
###                                          CLASSIFICATION                                            ###
##########################################################################################################
N_reps <- 100
DATA_TYPE <- "species_A1T1"  # {age , species_A1T1, species_A4E4}
V_reduction <- c("pca")
V_smooth <- c(T,F)
V_functional <- c(T,F)
n_modelTypes <- nrow(expand.grid(V_reduction,V_smooth,V_functional))
ALL_RES <- matrix(NA, 8, 13); rownames(ALL_RES) <- c("GLM","sGLM","pGLM","spGLM","fGLM","fsGLM","fpGLM","fspGLM"); colnames(ALL_RES) <- c("K/P","Q","R","lambda","acc","err_cv_smoothest","err_cv_stdev_smoothest","err_cv_ensemble","err_cv_stdev_ensemble","err_alt_smoothest","err_alt_stdev_smoothest","err_alt_ensemble","err_alt_stdev_ensemble")
L_load <- F   # ={TRUE,FALSE}, whether to load previous results (TRUE) or generate new results (FALSE)
iii <- 0
start_time <- Sys.time()
for(vr in V_reduction){
for(vs in V_smooth){
for(vf in V_functional){
if(!(L_load %in% c(T,F))){ stop("'L_load' must be either TRUE or FALSE.") }
if(DATA_TYPE == "species_A1T1"){
SPE <- c("arabiensis","gambiae")  # species: {arabiensis , coluzzii , gambiae};  age: {ARAB , GAMB , COLU}
LOC_train <- c("Longo")           # {Longo , Klesso}
LOC_test  <- c("Klesso")          # {Longo , Klesso}
GEN_train <- c("F0","F1")               # {F0 , F1 , F0F1}
#locTrain <- "Longo"
ii <- (raw_data[,"Species"] %in% SPE) & (raw_data[,"Location"] %in% LOC_train) & (raw_data[,"Generation"] %in% GEN_train)
X_subset <- X[ii,];  y_subset <- rep(0, sum(ii));  y_subset[raw_data[ii,"Species"] == SPE[1]] <- 1;
L_task <- "clas"; L_model <- "glm"
}else if(DATA_TYPE == "species_???"){
;
}else if(DATA_TYPE == "age"){
SPE <- "COLU"   # species: {ARABvsGAMB , ARABvsCOLU , COLUvsGAMB}; age: {ARAB , GAMB , COLU}
ii <- (raw_data[,"Species"] == "coluzzii")
X_subset <- X[ii,];  y_subset <- y[ii]
L_task <- "regr"; L_model <- "lm"
}else{
stop("'DATA_TYPE' invalid.")
}
#
L_reduction <- vr
L_smooth <- vs
L_functional <- vf
# smooth here, so use 'smooth=F' in fdaML_train()
if(L_smooth){ X_subset <- fdaSmooth(X_subset) }
N <- ifelse( abs(nrow(X_subset)-length(y_subset)) == 0, nrow(X_subset), stop("'nrow(X)' different from 'length(y)'") );  P <- ncol(X_subset);  palette(rich.colors(length(unique(y_subset))))
# matplot(wvlenghts, t(X_subset), type="l", col=alpha(as.numeric(sum(y_subset==0)!=0)+y_subset,0.4), lty=1, ylim=c(0,2), xlab="wavelength", ylab="signal"); legend("topright", paste("y=",sort(unique(y_subset)),sep=""), horiz=T, lty=1, seg.len=0.8, col=1:length(unique(y_subset)), bty="n", cex=0.8)
########
################   OPTIMISE {# basis K}
########
if(L_functional){
B_opt <- 0.1
#   tau_K <- 0.01
#   vec_basis <- seq(0.1, 1, by=0.1); lb <- length(vec_basis)
#   acc_basis <- rep(NA, lb)
#   cat("",paste0("DETERMINING OPTIMAL FUNCTIONAL REPRESENTATION:"), sep="\n")
#   pb_fda = txtProgressBar(min = 0, max = lb, initial = 0, style = 3);
#   for(nb in 1:lb){
#     set.seed(17571);  obj <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth_weights=NULL, intercept=T, lam_cv_type="n", lam_vec=NULL, reps=N_reps, Q_len=NULL, Q_opt=NULL, Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=F, estimation_weights=NULL, bspline_dim=floor(vec_basis[nb] * ncol(X)), t_range=wvlenghts, verbose=F))
#     acc_basis[nb] <- mean(obj$perf_cv[,which(obj$Q_vec == obj$Q_opt)])
#     setTxtProgressBar(pb_fda, nb)
#   } # plot(vec_basis, acc_basis, type="l", ylim = c(0.99*min(acc_basis), max(acc_basis))); abline(h = max(acc_basis) - 0.01, col="blue")
#   B_opt <- vec_basis[which((max(acc_basis) - acc_basis) < tau_K)[1]]
}else{
B_opt <- 1
}
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"GLM"),  "K/P"] <- B_opt
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), "K/P"] <- B_opt
########
################   OPTIMISE {# components "Q", penalty parameter "lambda"}
########
#---# Cross-validate (Q,lambda)
vec_basis      <- seq(B_opt, B_opt, by=0.2); lb <- length(vec_basis)
paramsByModel <- list(pls = list(comp_p   = floor(seq(16, 40, len=10)), lam_p   = round(seq(0.5,   10,  len=10), 1),
comp_sp  = floor(seq(16, 30, len=10)), lam_sp  = round(seq(50,    100, len=10), 1),
comp_fp  = floor(seq(16, 30, len=10)), lam_fp  = round(seq(25,    100, len=10), 1),
comp_fsp = floor(seq(10, 30, len=10)), lam_fsp = round(seq(5,     150, len=10), 1)),
pca = list(comp_p   = floor(seq(30, 63, len=10)), lam_p   = round(seq(0.1,   7,   len=10), 1),  # Q=63 is the largest possible b/c of sample sizes
comp_sp  = floor(seq(16, 50, len=10)), lam_sp  = round(seq(0.1,   120, len=10), 1),
comp_fp  = floor(seq(10, 46, len=10)), lam_fp  = round(seq(0.01,  14,  len=10), 1),
comp_fsp = floor(seq(6,  50, len=10)), lam_fsp = round(seq(0.01,  14,  len=10), 1)))
vec_components <- paramsByModel[[L_reduction]][[paste0("comp_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), "p")]];  lc <- length(vec_components)
vec_lambdas    <- paramsByModel[[L_reduction]][[paste0("lam_",  ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), "p")]];  ll <- length(vec_lambdas)
arr_acc <- arr_acc_stdev <- array(NA, c(length(vec_components), length(vec_lambdas), length(vec_basis)), dimnames=list(paste0("c_",vec_components), paste0("l_",vec_lambdas), paste0("b_",vec_basis)))
arr_rough <- arr_roughStd <- arr_acc
if(L_load){ # load data
loadedData <- readRDS(file=paste0(loc_data, DATA_TYPE, "_CV_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"), ".Rdata"))
arr_acc <- loadedData$arr_acc;  arr_acc_stdev <- loadedData$arr_acc_stdev;  arr_rough <- loadedData$arr_rough;  arr_roughStd <- loadedData$arr_roughStd;  vec_basis <- loadedData$vec_basis;  vec_components <- loadedData$vec_components;  vec_lambdas <- loadedData$vec_lambdas
}else{
cat("",paste0("Parameter set ",(iii+1),"/", n_modelTypes, " (vr=", L_reduction, ",vs=", ifelse(L_smooth==T,"T","F"), ",vf=", ifelse(L_functional==T,"T","F") ,") | CROSS-VALIDATING Q/LAMBDA:"), sep="\n")
pb_cv = txtProgressBar(min = 0, max = lb*lc*ll, initial = 0, style = 3);   loopCounter <- 0
for(nb in 1:lb){
for(nc in 1:lc){
for(nl in 1:ll){
set.seed(17571);  obj <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth_weights=NULL, intercept=T, lam_cv_type="ocv", lam_vec=vec_lambdas[nl], reps=N_reps, Q_len=NULL, Q_opt=vec_components[nc], Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=F, estimation_weights=NULL, bspline_dim=floor(vec_basis[nb] * ncol(X)), t_range=wvlenghts, verbose=F))
arr_acc[nc,nl,nb] <- mean(obj$perf_cv[,which(obj$Q_vec == obj$Q_opt)])
arr_acc_stdev[nc,nl,nb] <- sd(obj$perf_cv[,which(obj$Q_vec == obj$Q_opt)])
arr_rough[nc,nl,nb] <- mean(obj$beta_roughness)
arr_roughStd[nc,nl,nb] <- mean(obj$beta_roughnessStd)
loopCounter <- loopCounter + 1;   setTxtProgressBar(pb_cv, loopCounter)
}
}
}
cv_list <- list(arr_acc = arr_acc,
arr_acc_stdev = arr_acc_stdev,
arr_rough = arr_rough,
arr_roughStd = arr_roughStd,
vec_basis = vec_basis,
vec_components = vec_components,
vec_lambdas = vec_lambdas)
saveRDS(cv_list, file=paste0(loc_data, DATA_TYPE,"_CV_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"), ".Rdata"))
}
#---# Diagnostic plots
# set.seed(17571);  obj_dgnostics <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth_weights=NULL, intercept=T, lam_cv_type="n", lam_vec=NULL, reps=N_reps, Q_len=NULL, Q_opt=NULL, Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=F, estimation_weights=NULL, bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=T))
# fdaPlot(obj_dgnostics)
#---# Determine parameter region for ensemble meodel
B_id <- 1 # this is the first (and only) element of 'arr_acc' and similar arrays, because 'vec_basis' only has the optimal pre-computed ratio K/P = B_opt
matrix_acc <- arr_acc[,,B_id]
tau_lam_Q <- 0.01
n_acceptable <- 25  # maximum number of models in the acceptable region
n_ensemble   <- 5   # maximum number of models in the ensemble (most SMOOTH from the models in the acceptable region)
if(n_ensemble > n_acceptable){ stop("'n_acceptable' must be larger or equal to 'n_ensemble'.") }
# compute acceptable region
if(L_model == "lm"){
stop("REVISE OPTIMAL REGION FORMULA + MULTIPLE MODELS NOT CODED YET.")
acceptable_region <- which( (matrix_acc - min(matrix_acc)) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA); colnames(acceptable_region) <- c("components","lambda","roughness")
}else if (L_model == "glm"){
acceptable_region <- which( (max(matrix_acc) - matrix_acc) <= tau_lam_Q, arr.ind=T); nr <- nrow(acceptable_region); acceptable_region <- cbind(acceptable_region,NA,NA); colnames(acceptable_region) <- c("components","lambda","roughness","acc")
}
for(q in 1:nr){
acceptable_region[q,"roughness"] <- arr_roughStd[acceptable_region[q,"components"], acceptable_region[q,"lambda"], B_id]
acceptable_region[q,"acc"] <- matrix_acc[acceptable_region[q,"components"], acceptable_region[q,"lambda"]]
}
# order by 'acc' and select top 'n_acceptable'
acceptable_region <- acceptable_region[order(acceptable_region[,"acc"], decreasing=T),]
if(nrow(acceptable_region) > n_acceptable){ acceptable_region <- acceptable_region[1:n_acceptable,] # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_acceptable'
}else{                                      n_acceptable <- nrow(acceptable_region) }
if(n_acceptable < n_ensemble){ n_ensemble <- n_acceptable } # update since the number of model within the margin of error defined ('tau_lam_Q') may be smaller than the initially defined parameter 'n_ensemble'
# re-order by increasing roughness
acceptable_region <- acceptable_region[order(acceptable_region[,"roughness"]),]
# select best models
best_combo_IDs <- acceptable_region[, c("components","lambda")]
best_combo <- cbind(vec_components[best_combo_IDs[,"components"]], vec_lambdas[best_combo_IDs[,"lambda"]]); colnames(best_combo) <- c("Q_opt", "lam_opt")
#---# Levelplot for accuracy and roughness
brewer.div <- colorRampPalette(brewer.pal(11, "Spectral"), interpolate = "spline")
precision <- 3  # decimal places
plotMe_acc <- round(arr_acc[,,B_id], precision); rownames(plotMe_acc) <- vec_components; colnames(plotMe_acc) <- round(vec_lambdas,2)
plotMe_rough <- arr_roughStd[,,B_id]; rownames(plotMe_rough) <- vec_components; colnames(plotMe_rough) <- round(vec_lambdas,2)
# accuracy plot
# pdf(file = paste0(loc_figures, "fig_MAP_accuracy2.pdf"), height=5, width=5, pointsize=12)
colors_at <- seq(floor((10^precision)*min(plotMe_acc))/(10^precision), ceiling((10^precision)*max(plotMe_acc))/(10^precision), len=16)
the_labels <- round(colors_at,3);   the_labels[c(2,3,5,6,8,9,11,12,14,15)] <- ""
levelplot(plotMe_acc, at=colors_at, panel=crossvalidation_levelplot, letter=list(char="a", xloc=1, yloc=ncol(plotMe_acc)), col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="AUC map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
# roughness plot
# pdf(file = paste0(loc_figures, "fig_MAP_roughness2.pdf", height=5, width=5, pointsize=12)
colors_at <- exp(seq(log(min(plotMe_rough)*0.95), log(max(plotMe_rough)*1.05), len=16))
the_labels <- round(colors_at,2);   the_labels[c(2,3,4,5,6,7,8,10,12)] <- ""
levelplot(plotMe_rough, at=colors_at, panel=crossvalidation_levelplot, letter=list(char="b", xloc=1, yloc=ncol(plotMe_acc)), col.regions=brewer.div(100), colorkey=list(space="bottom", labels=list(labels=the_labels, at=colors_at)), par.settings=list(layout.heights=list(xlab.key.padding=2)), pretty=T, main="ROUGHNESS map", xlab=expression("components ("*Q*")"), ylab=expression("penalty parameter ("*lambda*")"), note_x=best_combo_IDs[,"components"], note_y=best_combo_IDs[,"lambda"])
# dev.off()
if( !(max(matrix_acc) - matrix_acc[best_combo_IDs[1,"components"], best_combo_IDs[1,"lambda"]] <= tau_lam_Q) ){ stop("Closeness criterion not satisfied!") }   # check that the result satisfies the criterion
#---# Test optimal and sub-optimal
cat("",paste0("Parameter set ",(iii+1),"/",n_modelTypes, " (vr=", L_reduction, ",vs=", ifelse(L_smooth==T,"T","F"), ",vf=", ifelse(L_functional==T,"T","F") ,") | COMPUTING OPTIMAL AND SUBOPTIMAL MODELS:"), sep="\n")
pb_subopt = txtProgressBar(min = 0, max = n_ensemble+1, initial = 0, style = 3)
set.seed(17571);  obj_std <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth_weights=NULL, intercept=T, lam_cv_type="n", lam_vec=NULL, reps=N_reps, Q_len=NULL, Q_opt=NULL, Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=F, estimation_weights=NULL, bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=F))
setTxtProgressBar(pb_subopt, 1)
suboptimal_MODELS <- list(); suboptimal_RES <- matrix(NA, n_ensemble, 8); colnames(suboptimal_RES) <- c("Q", "R", "lam", "acc", "err_cv", "err_cv_stdev", "err_alt", "err_alt_stdev")
for(jj in 1:n_ensemble){
set.seed(17571);  obj_opt <- fdaML_train(ll = list(X=X_subset, y=y_subset, Z=NULL, task=L_task, model=L_model, reduction=L_reduction, smooth_weights=NULL, intercept=T, lam_cv_type="ocv", lam_vec=best_combo[jj,"lam_opt"], reps=N_reps, Q_len=NULL, Q_opt=best_combo[jj,"Q_opt"], Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=F, estimation_weights=NULL, bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=F))
suboptimal_RES[jj,"Q"] <- obj_opt$Q_opt
suboptimal_RES[jj,"R"] <- GET_roughness(rowMeans(obj_opt$beta), std=T)
suboptimal_RES[jj,"lam"] <- obj_opt$lam_opt
suboptimal_RES[jj,"acc"] <- mean(obj_opt$AUC_opt[,"test"])
suboptimal_RES[jj,"err_cv"] <- fdaPlot(obj_opt)$err
suboptimal_RES[jj,"err_cv_stdev"] <- fdaPlot(obj_opt)$err_stdev
suboptimal_MODELS[[jj]] <- obj_opt
setTxtProgressBar(pb_subopt, jj+1)
}
# fdaPlot(obj_std, hist_range=c(-20,20))
# fdaPlot(obj_opt)
#{"Q","R","lambda","acc"}
if(L_model == "lm"){
stop("NOT CODED YET! calls 'obj_std$AUC_opt' but that only works for GLM.")
}else if(L_model == "glm"){
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"GLM"),  c("Q","R","lambda","acc","err_cv_smoothest","err_cv_stdev_smoothest")] <- c(obj_std$Q_opt, GET_roughness(rowMeans(obj_std$beta), std=T), obj_std$lam_opt, mean(obj_std$AUC_opt[,"test"]), fdaPlot(obj_std)$err, fdaPlot(obj_std)$err_stdev) # for the non-penalised model, we record the error in the 'smoothest' column, although there's only one model here (lambda=0)
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("Q","R","lambda","acc","err_cv_smoothest","err_cv_stdev_smoothest","err_cv_ensemble","err_cv_stdev_ensemble")] <- c(mean(suboptimal_RES[,"Q"]), mean(suboptimal_RES[,"R"]), mean(suboptimal_RES[,"lam"]), mean(suboptimal_RES[,"acc"]), unname(suboptimal_RES[1,"err_cv"]), unname(suboptimal_RES[1,"err_cv_stdev"]), mean(suboptimal_RES[,"err_cv"]), mean(suboptimal_RES[,"err_cv_stdev"]))
}
#---# P-values for non-functional variable
# ii_Zpvalues <- (raw_data[,"Species"] %in% SPE) & (raw_data[,"Location"] %in% c(LOC_train,LOC_test)) & (raw_data[,"Generation"] %in% GEN_train)
# balanced_classes <- T
# set.seed(17571);  obj_Zpvalues <- fdaML_train(ll = list(X=X[ii_Zpvalues,], y=factor(y[ii_Zpvalues]), Z=matrix(as.numeric(raw_data[ii_Zpvalues,"Location",drop=F] == "Klesso"), sum(ii_Zpvalues), 1), task=L_task, model=L_model, reduction=L_reduction, smooth_weights=NULL, intercept=T, lam_cv_type="n", lam_vec=NULL, reps=N_reps, Q_len=NULL, Q_opt=NULL, Q_vec=NULL, split_size=0.5, tau_Q_opt=0.01, balanced=balanced_classes, estimation_weights=NULL, bspline_dim=floor(B_opt * ncol(X)), t_range=wvlenghts, verbose=T))
# plot(obj_Zpvalues$Z_pvalue);  abline(h=0.05, lwd=2);  legend("topright", legend=paste0("median p-value = ", round(median(obj_Zpvalues$Z_pvalue),3)), bty="n", cex=0.9)
#---# Test with alternative dataset
#ii <- (raw_data[,"Feeding_status"] == "Exposed") & (raw_data[,"Infection_status"] %in% c("infectious","uninfectious")) & (raw_data[,"Scanning_day"] %in% c(17,19))
#X_subset_alt <- X[ii,];  y_subset_alt <- rep(0, sum(ii));  y_subset_alt[y[ii] == "infectious"] <- 1;
#
if(DATA_TYPE == "species_A1T1"){
# test with alternative dataset (species_A1T1)
GEN_test <- c("F0", "F1")
ii <- (raw_data[,"Species"] %in% SPE) & (raw_data[,"Location"] %in% LOC_test) & (raw_data[,"Generation"] %in% GEN_train)
X_subset_alt <- X[ii,];  y_subset_alt <- rep(0, sum(ii));  y_subset_alt[raw_data[ii,"Species"] == SPE[1]] <- 1
}else if(DATA_TYPE == "age"){
# test with alternative dataset (age)
ii <- (raw_data[,"Species"] %in% c("gambiae"))
X_subset_alt <- X[ii,];  y_subset_alt <- y[ii]
locTest <- "--"
}else{
stop("'DATA_TYPE' invalid.")
}
cat("",paste0("Parameter set ",(iii+1),"/", n_modelTypes, " (vr=", L_reduction, ",vs=", ifelse(L_smooth==T,"T","F"), ",vf=", ifelse(L_functional==T,"T","F") ,") | TESTING ALTERNATIVE DATASET:"), sep="\n")
pb_alt = txtProgressBar(min = 0, max = n_ensemble+1, initial = 0, style = 3)
set.seed(17571);  obj_alt_penNOP <- fdaML_predict(obj = obj_std, new_x = X_subset_alt, new_y = y_subset_alt, verbose=F)
setTxtProgressBar(pb_alt, 1)
# obj_alt_penNOP$errorBreakdown   # confusion matrix
alternative_MODELS <- list()
for(jj in 1:n_ensemble){
set.seed(17571);  obj_alt_penYEP <- fdaML_predict(obj = suboptimal_MODELS[[jj]], new_x = X_subset_alt, new_y = y_subset_alt, verbose=F)
# obj_alt_penYEP$errorBreakdown   # confusion matrix
#alternative_MODELS[[jj]] <- alternativeMODELS
suboptimal_RES[jj,"err_alt"] <- obj_alt_penYEP$avgTestErr
suboptimal_RES[jj,"err_alt_stdev"] <- obj_alt_penYEP$stdevTestErr
setTxtProgressBar(pb_alt, jj+1)
}
# re-order by increasing roughness
#suboptimal_RES <- suboptimal_RES[order(suboptimal_RES[,"R"]),]
write.table(x = round(suboptimal_RES, 8), file = paste0(loc_data, DATA_TYPE, "_suboptimalRESULTS_", ifelse(L_functional,"f",""), ifelse(L_smooth,"s",""), "p", toupper(L_model) ,"_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
#fdaPlot(obj_alt_penNOP)
#fdaPlot(obj_alt_penYEP)
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""), "GLM"), c("err_alt_smoothest", "err_alt_stdev_smoothest")] <- c(obj_alt_penNOP$avgTestErr, obj_alt_penNOP$stdevTestErr) # for the non-penalised model, we record the error in the 'smoothest' column, although there's only one model here (lambda=0)
#ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("err_alt", "err_alt_stdev")] <- c(obj_alt_penYEP$avgTestErr, obj_alt_penYEP$stdevTestErr)
ALL_RES[paste0(ifelse(L_functional,"f",""),ifelse(L_smooth,"s",""),"pGLM"), c("err_alt_smoothest", "err_alt_stdev_smoothest", "err_alt_ensemble", "err_alt_stdev_ensemble")] <- c(suboptimal_RES[1,"err_alt"], suboptimal_RES[1,"err_alt_stdev"], mean(suboptimal_RES[,"err_alt"]), mean(suboptimal_RES[jj,"err_alt_stdev"]))
#---# save summary results
iii <- iii + 1
if(DATA_TYPE == "species_A1T1"){
#saveRDS(ALL_RES, file=paste0(loc_data, DATA_TYPE,"_RESULTS__GLM_",toupper(L_reduction), "_", get_fname(SPE,"spe"), "_TrainOn_", LOC_train, get_fname(GEN_train,"gen"),"_TestOn_", LOC_test, get_fname(GEN_test,"gen"), "__iii-", iii, ".Rdata"))
write.table(x = round(ALL_RES,8), file = paste0(loc_data, DATA_TYPE,"_summaryRESULTS_", toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
}else if(DATA_TYPE == "age"){
write.table(x = round(ALL_RES,8), file = paste0(loc_data, DATA_TYPE,"_summaryRESULTS_", toupper(L_model), "_", toupper(L_reduction), "_reps", N_reps, "_", get_fname(SPE,"spe"), "_TrainOn", LOC_train, get_fname(GEN_train,"gen"),"_TestOn", LOC_test, get_fname(GEN_test,"gen"), ".txt"), sep=",")
}
end_time <- Sys.time()
cat("", paste0("cumulative time = ", round(end_time - start_time, 2), " ", attr(end_time - start_time, "units")), sep="\n")
# loaded_RES <- readRDS(loc_data, "species_A1T1_RESULTS__GLM_PLS_arabVSgamb_TrainOn_LongoF0F1_TestOn_KlessoF0F1.RData")
}#vf
}#vs
}#vr
